{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nengolib","metadata":{"id":"qYahiHxsgZil","outputId":"24a7f475-4008-4157-f17f-b0cc99575808","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom sympy.matrices import Matrix, eye, zeros, ones, diag, GramSchmidt\nimport numpy as np\nfrom functools import partial\nimport torch.nn.functional as F\nimport math\n\nfrom nengolib.signal import Identity, cont2discrete\nfrom nengolib.synapses import LegendreDelay\nfrom functools import partial\n\ndef lecun_uniform(tensor):\n    fan_in = nn.init._calculate_correct_fan(tensor, 'fan_in')\n    nn.init.uniform_(tensor, -math.sqrt(3 / fan_in), math.sqrt(3 / fan_in))\n    \nclass LegendreMemoryUnitCell(nn.Module):\n  def __init__(self, input_dim, units , order, theta,\n                 input_encoders_initializer=lecun_uniform,\n                 hidden_encoders_initializer=lecun_uniform,\n                 memory_encoders_initializer=partial(torch.nn.init.constant_, val=0),\n                 input_kernel_initializer=torch.nn.init.xavier_normal_,\n                 hidden_kernel_initializer=torch.nn.init.xavier_normal_,\n                #  hidden_kernel_initializer=torch.nn.init.uniform_,\n                 include_bias=False, #added by ali acc to branch\n                 memory_kernel_initializer=torch.nn.init.xavier_normal_):\n    super(LegendreMemoryUnitCell, self).__init__()\n\n    self.order = order\n    self.theta = theta\n    self.units = units\n    self.include_bias=include_bias\n\n    realizer = Identity()\n    self._realizer_result = realizer(LegendreDelay(theta=theta, order=self.order))\n\n    self._ss = cont2discrete(self._realizer_result.realization, dt=1., method='zoh')\n\n    self._A = self._ss.A - np.eye(order)\n    self._B = self._ss.B\n    self._C = self._ss.C\n\n    self.AT = nn.Parameter(torch.Tensor(self._A), requires_grad=False)\n    self.BT = nn.Parameter(torch.Tensor(self._B), requires_grad=False)\n\n    if self.include_bias:\n      self.bias = nn.Parameter(torch.Tensor(1, self.units),requires_grad=True) #added by ali for the fix given in github issue\n\n    self.encoder_input = nn.Parameter(torch.Tensor(1,input_dim), requires_grad=True)\n    self.encoder_hidden = nn.Parameter(torch.Tensor(1,self.units), requires_grad=True)\n    self.encoder_memory = nn.Parameter(torch.Tensor(1,self.order ), requires_grad=True)\n    self.kernel_input = nn.Parameter(torch.Tensor(self.units, input_dim), requires_grad=True)\n    self.kernel_hidden = nn.Parameter(torch.Tensor(self.units, self.units), requires_grad=True)\n    self.kernel_memory = nn.Parameter(torch.Tensor(self.units, self.order), requires_grad=True)\n    \n    if self.include_bias:\n      torch.nn.init.constant_(self.bias, 0)\n\n    input_encoders_initializer(self.encoder_input)\n    hidden_encoders_initializer(self.encoder_hidden)\n    memory_encoders_initializer(self.encoder_memory)\n    input_kernel_initializer(self.kernel_input)\n    hidden_kernel_initializer(self.kernel_hidden)\n    memory_kernel_initializer(self.kernel_memory)\n\n  def EulerOdeSolver(self):\n    A_hat = (self.step_delta_t/self.theta)*self.AT + torch.eye(self.order,self.d_order_ode)\n    B_hat = (self.step_delta_t/self.theta)*self.BT\n\n    return A_hat, B_hat\n\n  def forward(self, xt, states):\n    ht, mt = states\n\n    ut = F.linear(xt, self.encoder_input)+F.linear(ht, self.encoder_hidden)+  F.linear(mt, self.encoder_memory)\n\n\n    mt = mt + F.linear(mt, self.AT) + F.linear(ut, self.BT)\n\n    ht = nn.Tanh()(F.linear(xt, self.kernel_input) + F.linear(ht, self.kernel_hidden) + F.linear(mt, self.kernel_memory)+(self.bias if self.include_bias else 0))\n    \n    return ht, (ht, mt)\n\nclass LegendreMemoryUnit(nn.Module):\n  def __init__(self, input_dim, units , order, theta):\n    super(LegendreMemoryUnit, self).__init__()\n\n    self.units = units\n    self.order = order\n\n    self.lmucell = LegendreMemoryUnitCell(input_dim, units , order, theta,include_bias=False)\n\n  def forward(self, xt):\n    outputs = []\n    \n    h0 = torch.zeros(xt.size(0),self.units).cuda()\n    m0 = torch.zeros(xt.size(0),self.order).cuda()\n    states = (h0,m0)\n    for i in range(xt.size(1)):\n      out, states = self.lmucell(xt[:,i,:], states)\n      outputs += [out]\n    return torch.stack(outputs).permute(1,0,2), states\n    # return torch.stack(outputs).permute(1,0,2), states\n","metadata":{"id":"mAiRtAIA3kM4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test LMU output","metadata":{"id":"tRC62TebNYWJ"}},{"cell_type":"code","source":"x = torch.rand(64,5000,1).to(torch.device(\"cuda:0\"))\nh0 = torch.rand(64,49).to(torch.device(\"cuda:0\"))\nm0 = torch.rand(64,4).to(torch.device(\"cuda:0\"))\nmodel = LegendreMemoryUnit(1,49,4,4).to(torch.device(\"cuda:0\"))\nres, _ = model(x)\nprint(res.shape)","metadata":{"id":"JfTlZrsfbSXH","outputId":"07bc6c96-be05-4e12-eade-fbd26cc68420","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models LSTM - LMU","metadata":{"id":"mRuoDB59NvMX"}},{"cell_type":"code","source":"class LMUModel(nn.Module):\n  def __init__(self):\n    super(LMUModel, self).__init__()\n    self.LMU = LegendreMemoryUnit(1,49,4,4)\n    self.dense = nn.Linear(49,10)\n\n  def forward(self,x):\n    x, _ = self.LMU(x)\n    x = self.dense(x[:,-1,:])\n\n    return x\n\nmodel_lstm = LMUModel()\n\nprint(\"number of parameters : \", sum(p.numel() for p in model_lstm.parameters() if p.requires_grad))\nprint()\n","metadata":{"id":"51nVz6TsX9Fc","outputId":"fa356998-c55e-4160-c385-cb544e4bb6c4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n  def __init__(self):\n    super(LSTMModel, self).__init__()\n    self.LSTM = nn.LSTM(1,25,1,batch_first=True)\n    self.dense = nn.Linear(25,10)\n\n  def forward(self,x):\n    x, _ = self.LSTM(x)\n    x = self.dense(x[:,-1,:])\n\n    return x\n    \nmodel_lstm = LSTMModel()\n\nprint(\"number of parameters : \", sum(p.numel() for p in model_lstm.parameters() if p.requires_grad))\nprint()\n","metadata":{"id":"DrNF6LetOGun","outputId":"2093a157-1e85-4b5f-f305-e94e98777417","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MackeyGlass Datas","metadata":{"id":"soOI6lS9Ocas"}},{"cell_type":"markdown","source":"Took from official LMU (tensorflow) repo","metadata":{"id":"rOkZjfzqvhBD"}},{"cell_type":"code","source":"\n","metadata":{"id":"voyo-rQYD-56","outputId":"023eb0e3-f8a7-4175-99f8-88f645af8029"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"3xncoH8HPLsg"}},{"cell_type":"code","source":"def train(model, epochs, dataset, dataset_valid = None):\n  for e in range(epochs):\n      model.train()\n      running_loss = 0\n      with tqdm(total=len(dataset)) as bar:\n        for i, (X, y) in enumerate(dataset):\n            optimizer.zero_grad()\n            \n            output = model(X.cuda())\n            # print(output.shape)\n            # print(y.shape)\n            loss_ll = criterion(output, y.cuda())\n            \n            loss_ll.backward()\n            \n            optimizer.step()\n            \n            running_loss += loss_ll.item()\n\n            bar.update(1)\n            bar.set_description(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(dataset)))\n\n      model.eval()\n      running_loss = 0\n      outs = []\n      with tqdm(total=len(dataset_valid)) as bar:\n        for i, (X, y) in enumerate(dataset_valid):\n            optimizer.zero_grad()\n            \n            output = model(X.cuda())\n            # t1=output.detach().cpu().numpy()[0][-100:]\n            # t2=y.detach().cpu().numpy()[0][-100:]\n            loss_ll = criterion(output, y.cuda())\n            \n            running_loss += loss_ll.item()\n            \n            # outs.append(output)\n            bar.update(1)\n            bar.set_description(\"Epoch {} - Validation loss: {}\".format(e, running_loss/len(dataset_valid)))\n      # plt.plot(t1)\n      # plt.plot(t2)\n      # plt.show()\n","metadata":{"id":"yaCT4Pi_PakY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test LMU vs LSTM on MackeyGlass","metadata":{"id":"FEwfu8TUPTnI"}},{"cell_type":"markdown","source":"","metadata":{"id":"rUlSXcORWqtn"}},{"cell_type":"code","source":"","metadata":{"id":"2GIa1QmHpIr1","outputId":"04ee69cd-40c4-4b1d-cc65-212ca7b42a16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Qaunc4vo9Orw","outputId":"daf0bca2-a9e4-4339-c97f-2fb3f5b3b3d4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New section","metadata":{"id":"wQ9gHUDPDAZ6"}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nimport tensorflow as tf","metadata":{"id":"OsRAIkKZDB9O","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 0\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nrng = np.random.RandomState(seed)","metadata":{"id":"fFENTI3tDSLz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_images, train_labels), (\n    test_images,\n    test_labels,\n) = tf.keras.datasets.mnist.load_data()","metadata":{"id":"3a7YuTYmDWCK","outputId":"9c4dff7d-6767-42a5-ed2f-8bd54bfc3a60","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_images))","metadata":{"id":"C7MmEQLTDfHN","outputId":"2118674b-1b5a-4d19-b6b3-32b0b50e9c30","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_images / 255\ntest_images = test_images / 255\n\nplt.figure()\nplt.imshow(np.reshape(train_images[0], (28, 28)), cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(f\"Sample image of the digit '{train_labels[0]}'\")\nplt.show()","metadata":{"id":"Dc8RUOdCDnk0","outputId":"90824ffb-fa01-4d04-eb29-1bb417a151dc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_images.reshape((train_images.shape[0], -1, 1))\ntest_images = test_images.reshape((test_images.shape[0], -1, 1))\n\n# we'll display the sequence in 8 rows just so that it fits better on the screen\nplt.figure()\nplt.imshow(train_images[0].reshape(8, -1), cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(f\"Sample sequence of the digit '{train_labels[0]}' (reshaped to 98 x 8)\")\nplt.show()","metadata":{"id":"L9PyFbuUEXSQ","outputId":"904d9cf5-9617-4591-95b1-880bd4e1823c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perm = rng.permutation(train_images.shape[1])\ntrain_images = train_images[:, perm]\ntest_images = test_images[:, perm]\n\nplt.figure()\nplt.imshow(train_images[0].reshape(8, -1), cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(f\"Permuted sequence of the digit '{train_labels[0]}' (reshaped to 98 x 8)\")\nplt.show()","metadata":{"id":"I3e_Ct2XEq9d","outputId":"3890fec5-b7d6-401f-9461-0e26df9de0cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train_images[0:50000]\nX_valid = train_images[50000:]\nX_test = test_images\n\nY_train = train_labels[0:50000]\nY_valid = train_labels[50000:]\nY_test = test_labels\n\nprint(\n    f\"Training inputs shape: {X_train.shape}, \"\n    f\"Training targets shape: {Y_train.shape}\"\n)\nprint(\n    f\"Validation inputs shape: {X_valid.shape}, \"\n    f\"Validation targets shape: {Y_valid.shape}\"\n)\nprint(f\"Testing inputs shape: {X_test.shape}, Testing targets shape: {Y_test.shape}\")","metadata":{"id":"kzy5TDrDEvqM","outputId":"6f655f60-aad9-4efc-9f6c-74155961e34a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_X, train_Y_temp)= (X_train,Y_train.reshape(-1,1)) \n(test_X, test_Y_temp) = (X_test,Y_test.reshape(-1,1))\nprint(train_Y_temp.shape[0])\ntrain_Y=np.zeros((train_Y_temp.shape[0],10),dtype='int')\nprint(test_Y_temp.shape[0])\ntest_Y=np.zeros((test_Y_temp.shape[0],10),dtype='int')\ntrain_Y[np.arange(Y_train.size),Y_train] = 1\ntest_Y[np.arange(Y_test.size),Y_test] = 1\nprint(Y_train[:5])\nprint(train_Y[:5])\nprint(Y_test[:5])\nprint(test_Y[:5])\ntrain_Y=Y_train\ntest_Y=Y_test\nprint(train_X.shape, test_X.shape,train_Y.shape,test_Y.shape)\nprint(train_X[:5000].shape)","metadata":{"id":"XkA_q8H9H00i","outputId":"9924e039-664b-435b-caac-27a439fd53ae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM\n\nfrom tqdm import tqdm\nimport torch.utils.data as data\n\n\n\nmodel = LSTMModel().cuda()\nprint(\"\\nnumber of paramaters : \", sum(p.numel() for p in model.parameters() if p.requires_grad))\nprint(\"\\n\\n\")\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nmodel.train()\nprint(model)\ndataset = torch.utils.data.TensorDataset(torch.Tensor(train_X[:5000]).cuda(), torch.Tensor(train_Y[:5000]).long().cuda())\ndataset = data.DataLoader(dataset, batch_size=16, shuffle=True)\n\ndataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X[:1000]).cuda(), torch.Tensor(test_Y[:1000]).long().cuda())\ndataset_valid = data.DataLoader(dataset_valid, batch_size=16, shuffle=False)\n\ntrain(model, 100, dataset, dataset_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LMU\nfrom tqdm import tqdm\nimport torch.utils.data as data\n\n# training on only 5000 and testing on 1000\n\nmodel = LMUModel().cuda()\nprint(\"\\n\\number of paramaters : \", sum(p.numel() for p in model.parameters() if p.requires_grad))\nprint(\"\\n\\n\")\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nmodel.train()\nprint(model)\ndataset = torch.utils.data.TensorDataset(torch.Tensor(train_X[:5000]).cuda(), torch.Tensor(train_Y[:5000]).long().cuda())\ndataset = data.DataLoader(dataset, batch_size=32, shuffle=True)\n\ndataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X[:1000]).cuda(), torch.Tensor(test_Y[:1000]).long().cuda())\ndataset_valid = data.DataLoader(dataset_valid, batch_size=16, shuffle=False)\n\ntrain(model, 100, dataset, dataset_valid)","metadata":{"id":"GW9FuiMGIJ3q","outputId":"73bc18d8-afa1-4672-9409-68c0a02cda9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"lX1bhA4PpiSb","outputId":"a0a22c1d-32d6-4b42-f3c1-b500299b1e3b"},"execution_count":null,"outputs":[]}]}