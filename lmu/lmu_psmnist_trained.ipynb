{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "lmu_psmnist_trained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYahiHxsgZil",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125bb320-7aa9-4b93-e03f-46ecf33db59e"
      },
      "source": [
        "!pip install nengolib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nengolib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/00/62bbce813d135da3799f4afc26957d942d4ae27085fb0df1bfb57dcf692b/nengolib-0.5.2-py2.py3-none-any.whl (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 36.1MB/s \n",
            "\u001b[?25hCollecting nengo<3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/ce/e314e1176bfbbe6c3b6cf4e8fa0620cafad8f8bad04203c55881e9cb2fb0/nengo-2.8.0-py2.py3-none-any.whl (375kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.4.1)\n",
            "Installing collected packages: nengo, nengolib\n",
            "Successfully installed nengo-2.8.0 nengolib-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAiRtAIA3kM4",
        "trusted": true
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sympy.matrices import Matrix, eye, zeros, ones, diag, GramSchmidt\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from nengolib.signal import Identity, cont2discrete\n",
        "from nengolib.synapses import LegendreDelay\n",
        "from functools import partial\n",
        "\n",
        "def lecun_uniform(tensor):\n",
        "    fan_in = nn.init._calculate_correct_fan(tensor, 'fan_in')\n",
        "    nn.init.uniform_(tensor, -math.sqrt(3 / fan_in), math.sqrt(3 / fan_in))\n",
        "    \n",
        "class LegendreMemoryUnitCell(nn.Module):\n",
        "  def __init__(self, input_dim, units , order, theta,\n",
        "                 input_encoders_initializer=lecun_uniform,\n",
        "                 hidden_encoders_initializer=lecun_uniform,\n",
        "                 memory_encoders_initializer=partial(torch.nn.init.constant_, val=0),\n",
        "                 input_kernel_initializer=torch.nn.init.xavier_normal_,\n",
        "                 hidden_kernel_initializer=torch.nn.init.xavier_normal_,\n",
        "                #  hidden_kernel_initializer=torch.nn.init.uniform_,\n",
        "                 include_bias=False, #added by ali acc to branch\n",
        "                 memory_kernel_initializer=torch.nn.init.xavier_normal_):\n",
        "    super(LegendreMemoryUnitCell, self).__init__()\n",
        "\n",
        "    self.order = order\n",
        "    self.theta = theta\n",
        "    self.units = units\n",
        "    self.include_bias=include_bias\n",
        "\n",
        "    realizer = Identity()\n",
        "    self._realizer_result = realizer(LegendreDelay(theta=theta, order=self.order))\n",
        "\n",
        "    self._ss = cont2discrete(self._realizer_result.realization, dt=1., method='zoh')\n",
        "\n",
        "    self._A = self._ss.A - np.eye(order)\n",
        "    self._B = self._ss.B\n",
        "    self._C = self._ss.C\n",
        "\n",
        "    self.AT = nn.Parameter(torch.Tensor(self._A), requires_grad=False)\n",
        "    self.BT = nn.Parameter(torch.Tensor(self._B), requires_grad=False)\n",
        "\n",
        "    if self.include_bias:\n",
        "      self.bias = nn.Parameter(torch.Tensor(1, self.units),requires_grad=True) #added by ali for the fix given in github issue\n",
        "\n",
        "    self.encoder_input = nn.Parameter(torch.Tensor(1,input_dim), requires_grad=True)\n",
        "    self.encoder_hidden = nn.Parameter(torch.Tensor(1,self.units), requires_grad=True)\n",
        "    self.encoder_memory = nn.Parameter(torch.Tensor(1,self.order ), requires_grad=True)\n",
        "    self.kernel_input = nn.Parameter(torch.Tensor(self.units, input_dim), requires_grad=True)\n",
        "    self.kernel_hidden = nn.Parameter(torch.Tensor(self.units, self.units), requires_grad=True)\n",
        "    self.kernel_memory = nn.Parameter(torch.Tensor(self.units, self.order), requires_grad=True)\n",
        "    \n",
        "    if self.include_bias:\n",
        "      torch.nn.init.constant_(self.bias, 0)\n",
        "\n",
        "    input_encoders_initializer(self.encoder_input)\n",
        "    hidden_encoders_initializer(self.encoder_hidden)\n",
        "    memory_encoders_initializer(self.encoder_memory)\n",
        "    input_kernel_initializer(self.kernel_input)\n",
        "    hidden_kernel_initializer(self.kernel_hidden)\n",
        "    memory_kernel_initializer(self.kernel_memory)\n",
        "\n",
        "  def EulerOdeSolver(self):\n",
        "    A_hat = (self.step_delta_t/self.theta)*self.AT + torch.eye(self.order,self.d_order_ode)\n",
        "    B_hat = (self.step_delta_t/self.theta)*self.BT\n",
        "\n",
        "    return A_hat, B_hat\n",
        "\n",
        "  def forward(self, xt, states):\n",
        "    ht, mt = states\n",
        "\n",
        "    ut = F.linear(xt, self.encoder_input)+F.linear(ht, self.encoder_hidden)+  F.linear(mt, self.encoder_memory)\n",
        "\n",
        "\n",
        "    mt = mt + F.linear(mt, self.AT) + F.linear(ut, self.BT)\n",
        "\n",
        "    ht = nn.Tanh()(F.linear(xt, self.kernel_input) + F.linear(ht, self.kernel_hidden) + F.linear(mt, self.kernel_memory)+(self.bias if self.include_bias else 0))\n",
        "    \n",
        "    return ht, (ht, mt)\n",
        "\n",
        "class LegendreMemoryUnit(nn.Module):\n",
        "  def __init__(self, input_dim, units , order, theta):\n",
        "    super(LegendreMemoryUnit, self).__init__()\n",
        "\n",
        "    self.units = units\n",
        "    self.order = order\n",
        "\n",
        "    self.lmucell = LegendreMemoryUnitCell(input_dim, units , order, theta,include_bias=False)\n",
        "\n",
        "  def forward(self, xt):\n",
        "    outputs = []\n",
        "    \n",
        "    h0 = torch.zeros(xt.size(0),self.units).cuda()\n",
        "    m0 = torch.zeros(xt.size(0),self.order).cuda()\n",
        "    states = (h0,m0)\n",
        "    for i in range(xt.size(1)):\n",
        "      out, states = self.lmucell(xt[:,i,:], states)\n",
        "      outputs += [out]\n",
        "    return torch.stack(outputs).permute(1,0,2), states\n",
        "    # return torch.stack(outputs).permute(1,0,2), states\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRC62TebNYWJ"
      },
      "source": [
        "# Test LMU output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfTlZrsfbSXH",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3717bf-5416-48e8-e7d8-b5c1e16e4b73"
      },
      "source": [
        "x = torch.rand(64,5000,1).to(torch.device(\"cuda:0\"))\n",
        "h0 = torch.rand(64,49).to(torch.device(\"cuda:0\"))\n",
        "m0 = torch.rand(64,4).to(torch.device(\"cuda:0\"))\n",
        "model = LegendreMemoryUnit(1,49,4,4).to(torch.device(\"cuda:0\"))\n",
        "res, _ = model(x)\n",
        "print(res.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 5000, 49])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRuoDB59NvMX"
      },
      "source": [
        "# Models LSTM - LMU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51nVz6TsX9Fc",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ded8f9-b23f-4f4e-b81a-55554d8884ee"
      },
      "source": [
        "class LMUModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LMUModel, self).__init__()\n",
        "    self.LMU = LegendreMemoryUnit(1,212,256,784)\n",
        "    self.dense = nn.Linear(212,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x, _ = self.LMU(x)\n",
        "    x = self.dense(x[:,-1,:])\n",
        "\n",
        "    return x\n",
        "\n",
        "model_lstm = LMUModel()\n",
        "\n",
        "print(\"number of parameters : \", sum(p.numel() for p in model_lstm.parameters() if p.requires_grad))\n",
        "print()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of parameters :  102027\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrNF6LetOGun",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4024ee-0be3-4334-a69d-b44e5cf5a582"
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.LSTM = nn.LSTM(1,200,1,batch_first=True)\n",
        "    self.dense = nn.Linear(200,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x, _ = self.LSTM(x)\n",
        "    x = self.dense(x[:,-1,:])\n",
        "\n",
        "    return x\n",
        "    \n",
        "model_lstm = LSTMModel()\n",
        "\n",
        "print(\"number of parameters : \", sum(p.numel() for p in model_lstm.parameters() if p.requires_grad))\n",
        "print()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of parameters :  164410\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xncoH8HPLsg"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCT4Pi_PakY",
        "trusted": true
      },
      "source": [
        "import numpy as np\n",
        "def train(model, epochs, dataset, dataset_valid = None):\n",
        "  for e in range(epochs):\n",
        "      model.train()\n",
        "      running_loss = 0\n",
        "      sum_acc = 0      \n",
        "      with tqdm(total=len(dataset)) as bar:\n",
        "        for i, (X, y) in enumerate(dataset):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(X.cuda())\n",
        "            # print(output.shape)\n",
        "            # print(y.shape)\n",
        "            loss_ll = criterion(output, y.cuda())\n",
        "            \n",
        "            loss_ll.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            y_num=y.cpu().detach().numpy() \n",
        "            output_num=output.cpu().detach().numpy() \n",
        "            pred=np.argmax(output_num,axis=1)\n",
        "            acc=np.sum(pred==y_num)\n",
        "#             print(acc)\n",
        "            sum_acc+=(acc/len(pred))\n",
        "#             print(len(dataset))\n",
        "#             print(len(pred))\n",
        "            running_loss += loss_ll.item()\n",
        "\n",
        "            bar.update(1)\n",
        "            bar.set_description(\"Epoch {} - Training loss: {}, Accuracy={}\".format(e, running_loss/len(dataset),sum_acc/len(dataset)))\n",
        "\n",
        "      model.eval()\n",
        "      running_loss = 0\n",
        "      sum_acc = 0         \n",
        "      outs = []\n",
        "      with tqdm(total=len(dataset_valid)) as bar:\n",
        "        for i, (X, y) in enumerate(dataset_valid):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(X.cuda())\n",
        "            # t1=output.detach().cpu().numpy()[0][-100:]\n",
        "            # t2=y.detach().cpu().numpy()[0][-100:]\n",
        "            loss_ll = criterion(output, y.cuda())\n",
        "            y_num=y.cpu().detach().numpy() \n",
        "            output_num=output.cpu().detach().numpy() \n",
        "            pred=np.argmax(output_num,axis=1)\n",
        "            acc=np.sum(pred==y_num)\n",
        "#             print(acc)\n",
        "            sum_acc+=(acc/len(pred))\n",
        "#             print(pred)\n",
        "#             print(y_num)\n",
        "#             print(sum_acc,acc)\n",
        "            running_loss += loss_ll.item()\n",
        "            \n",
        "            # outs.append(output)\n",
        "            bar.update(1)\n",
        "            bar.set_description(\"Epoch {} - Validation loss: {}, Accuracy={}\".format(e, running_loss/len(dataset_valid),sum_acc/len(dataset_valid)))\n",
        "      # plt.plot(t1)\n",
        "      # plt.plot(t2)\n",
        "      # plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUlSXcORWqtn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ9gHUDPDAZ6"
      },
      "source": [
        "# psMNIST dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsRAIkKZDB9O",
        "trusted": true
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFENTI3tDSLz",
        "trusted": true
      },
      "source": [
        "seed = 0\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "rng = np.random.RandomState(seed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a7YuTYmDWCK",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5571dd7-01a1-4f0f-b020-dbcb90c61de0"
      },
      "source": [
        "(train_images, train_labels), (\n",
        "    test_images,\n",
        "    test_labels,\n",
        ") = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7MmEQLTDfHN",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8c1e6f-ba35-4ba5-bfb7-51d3ef92f14c"
      },
      "source": [
        "print(len(test_images))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc8RUOdCDnk0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "d602cc73-3b94-43be-a1b9-f0bd8041a073"
      },
      "source": [
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(train_images[0], (28, 28)), cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Sample image of the digit '{train_labels[0]}'\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9PyFbuUEXSQ",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5ffbb640-7aba-46b9-8f2f-cc681efb66c7"
      },
      "source": [
        "train_images = train_images.reshape((train_images.shape[0], -1, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], -1, 1))\n",
        "\n",
        "# we'll display the sequence in 8 rows just so that it fits better on the screen\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0].reshape(8, -1), cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Sample sequence of the digit '{train_labels[0]}' (reshaped to 98 x 8)\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3e_Ct2XEq9d",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "6ad01567-44a9-4ead-fcee-9fc1db8f633d"
      },
      "source": [
        "perm = rng.permutation(train_images.shape[1])\n",
        "train_images = train_images[:, perm]\n",
        "test_images = test_images[:, perm]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0].reshape(8, -1), cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Permuted sequence of the digit '{train_labels[0]}' (reshaped to 98 x 8)\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzy5TDrDEvqM",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed2b9a7-fde5-463c-890b-aa4997e0007d"
      },
      "source": [
        "X_train = train_images[0:50000]\n",
        "X_valid = train_images[50000:]\n",
        "X_test = test_images\n",
        "\n",
        "Y_train = train_labels[0:50000]\n",
        "Y_valid = train_labels[50000:]\n",
        "Y_test = test_labels\n",
        "\n",
        "print(\n",
        "    f\"Training inputs shape: {X_train.shape}, \"\n",
        "    f\"Training targets shape: {Y_train.shape}\"\n",
        ")\n",
        "print(\n",
        "    f\"Validation inputs shape: {X_valid.shape}, \"\n",
        "    f\"Validation targets shape: {Y_valid.shape}\"\n",
        ")\n",
        "print(f\"Testing inputs shape: {X_test.shape}, Testing targets shape: {Y_test.shape}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training inputs shape: (50000, 784, 1), Training targets shape: (50000,)\n",
            "Validation inputs shape: (10000, 784, 1), Validation targets shape: (10000,)\n",
            "Testing inputs shape: (10000, 784, 1), Testing targets shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkA_q8H9H00i",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a2b96c-4169-41cc-e57d-9d19e525fb55"
      },
      "source": [
        "(train_X, train_Y_temp)= (X_train,Y_train.reshape(-1,1)) \n",
        "(test_X, test_Y_temp) = (X_test,Y_test.reshape(-1,1))\n",
        "print(train_Y_temp.shape[0])\n",
        "train_Y=np.zeros((train_Y_temp.shape[0],10),dtype='int')\n",
        "print(test_Y_temp.shape[0])\n",
        "test_Y=np.zeros((test_Y_temp.shape[0],10),dtype='int')\n",
        "train_Y[np.arange(Y_train.size),Y_train] = 1\n",
        "test_Y[np.arange(Y_test.size),Y_test] = 1\n",
        "print(Y_train[:5])\n",
        "print(train_Y[:5])\n",
        "print(Y_test[:5])\n",
        "print(test_Y[:5])\n",
        "train_Y=Y_train\n",
        "test_Y=Y_test\n",
        "print(train_X.shape, test_X.shape,train_Y.shape,test_Y.shape)\n",
        "print(train_X[:5000].shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n",
            "[5 0 4 1 9]\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]]\n",
            "[7 2 1 0 4]\n",
            "[[0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]]\n",
            "(50000, 784, 1) (10000, 784, 1) (50000,) (10000,)\n",
            "(5000, 784, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epm92jbtV4dT"
      },
      "source": [
        "# # Normalisiing data manually b/w 0-1\n",
        "# # for i in range(0,train_X.shape[0]):\n",
        "\n",
        "# train_X_min=np.min(train_X.reshape(-1,784),axis=1)\n",
        "# train_X_max=np.max(train_X.reshape(-1,784),axis=1)\n",
        "# print(train_X_min.shape)\n",
        "# print(train_X_min[:10])\n",
        "# print(sum(train_X_max==1))\n",
        "# print(train_X.reshape(-1,784)[:5])\n",
        "# norm_train_X=((train_X.reshape(-1,784)-train_X_min.reshape((50000,1)))/(train_X_max.reshape((50000,1))-train_X_min.reshape((50000,1)))).reshape(50000,784,1)\n",
        "# print(norm_train_X.shape)\n",
        "# print(norm_train_X[0,:10,0])\n",
        "\n",
        "# test_X_min=np.min(test_X.reshape(-1,784),axis=1)\n",
        "# test_X_max=np.max(test_X.reshape(-1,784),axis=1)\n",
        "# print(test_X_min.shape)\n",
        "# print(test_X_min[:10])\n",
        "# print(sum(test_X_max==1))\n",
        "# print(test_X.reshape(-1,784)[:5])\n",
        "# norm_test_X=((test_X.reshape(-1,784)-test_X_min.reshape((10000,1)))/(test_X_max.reshape((10000,1))-test_X_min.reshape((10000,1)))).reshape(10000,784,1)\n",
        "# print(norm_test_X.shape)\n",
        "# print(norm_test_X[0,:10,0])\n",
        "# # image = (image - image.min())/(image.max() - image.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK0XYS9tHuM"
      },
      "source": [
        "# LMU on psMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YadtXTve0JFK",
        "outputId": "90aa5b7d-5aff-4f9f-ebfb-c95d713a0666"
      },
      "source": [
        "# LMU\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as data\n",
        "\n",
        "# training on only 5000 and testing on 1000\n",
        "\n",
        "model = LMUModel().cuda()\n",
        "print(\"\\n\\number of paramaters : \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"\\n\\n\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "model.train()\n",
        "print(model)\n",
        "dataset = torch.utils.data.TensorDataset(torch.Tensor(train_X[:50000]).cuda(), torch.Tensor(train_Y[:50000]).long().cuda())\n",
        "dataset = data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "dataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X[:10000]).cuda(), torch.Tensor(test_Y[:10000]).long().cuda())\n",
        "dataset_valid = data.DataLoader(dataset_valid, batch_size=16, shuffle=False)\n",
        "\n",
        "train(model, 40, dataset, dataset_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "umber of paramaters :  102027\n",
            "\n",
            "\n",
            "\n",
            "LMUModel(\n",
            "  (LMU): LegendreMemoryUnit(\n",
            "    (lmucell): LegendreMemoryUnitCell()\n",
            "  )\n",
            "  (dense): Linear(in_features=212, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 1.2690409023603109, Accuracy=0.5810340690978887: 100%|██████████| 1563/1563 [13:50<00:00,  1.88it/s]\n",
            "Epoch 0 - Validation loss: 0.790151309633255, Accuracy=0.7498: 100%|██████████| 625/625 [02:46<00:00,  3.76it/s]\n",
            "Epoch 1 - Training loss: 0.625476629295108, Accuracy=0.8060820537428023: 100%|██████████| 1563/1563 [13:17<00:00,  1.96it/s]\n",
            "Epoch 1 - Validation loss: 0.5069858173489571, Accuracy=0.8451: 100%|██████████| 625/625 [02:45<00:00,  3.78it/s]\n",
            "Epoch 2 - Training loss: 0.46411421717700485, Accuracy=0.8558861164427384: 100%|██████████| 1563/1563 [13:10<00:00,  1.98it/s]\n",
            "Epoch 2 - Validation loss: 0.45048632298707963, Accuracy=0.8603: 100%|██████████| 625/625 [02:43<00:00,  3.83it/s]\n",
            "Epoch 3 - Training loss: 0.38297383650250716, Accuracy=0.8809181062060141: 100%|██████████| 1563/1563 [13:09<00:00,  1.98it/s]\n",
            "Epoch 3 - Validation loss: 0.32315512564331295, Accuracy=0.9013: 100%|██████████| 625/625 [02:38<00:00,  3.95it/s]\n",
            "Epoch 4 - Training loss: 0.3354097334376071, Accuracy=0.8961932181701855: 100%|██████████| 1563/1563 [13:05<00:00,  1.99it/s]\n",
            "Epoch 4 - Validation loss: 0.3280263263300061, Accuracy=0.8961: 100%|██████████| 625/625 [02:39<00:00,  3.93it/s]\n",
            "Epoch 5 - Training loss: 0.29898847297777825, Accuracy=0.9058101407549584: 100%|██████████| 1563/1563 [12:57<00:00,  2.01it/s]\n",
            "Epoch 5 - Validation loss: 0.2890421808637679, Accuracy=0.9101: 100%|██████████| 625/625 [02:41<00:00,  3.88it/s]\n",
            "Epoch 6 - Training loss: 0.2710569668549303, Accuracy=0.914427383237364: 100%|██████████| 1563/1563 [12:51<00:00,  2.03it/s]\n",
            "Epoch 6 - Validation loss: 0.25387087285444143, Accuracy=0.921: 100%|██████████| 625/625 [02:38<00:00,  3.94it/s]\n",
            "Epoch 7 - Training loss: 0.24743711387336978, Accuracy=0.9217450415866922: 100%|██████████| 1563/1563 [12:51<00:00,  2.03it/s]\n",
            "Epoch 7 - Validation loss: 0.2570364931277931, Accuracy=0.9208: 100%|██████████| 625/625 [02:37<00:00,  3.98it/s]\n",
            "Epoch 8 - Training loss: 0.2294739659170138, Accuracy=0.9274832053742802: 100%|██████████| 1563/1563 [12:52<00:00,  2.02it/s]\n",
            "Epoch 8 - Validation loss: 0.24096084206923843, Accuracy=0.9241: 100%|██████████| 625/625 [02:36<00:00,  3.99it/s]\n",
            "Epoch 9 - Training loss: 0.21150743631051372, Accuracy=0.9346809021113244: 100%|██████████| 1563/1563 [12:56<00:00,  2.01it/s]\n",
            "Epoch 9 - Validation loss: 0.22781321981362998, Accuracy=0.9306: 100%|██████████| 625/625 [02:39<00:00,  3.93it/s]\n",
            "Epoch 10 - Training loss: 0.19856891846159141, Accuracy=0.9369001919385797: 100%|██████████| 1563/1563 [12:57<00:00,  2.01it/s]\n",
            "Epoch 10 - Validation loss: 0.22177470932491122, Accuracy=0.9321: 100%|██████████| 625/625 [02:38<00:00,  3.94it/s]\n",
            "Epoch 11 - Training loss: 0.18607611630543333, Accuracy=0.9420585412667947: 100%|██████████| 1563/1563 [12:50<00:00,  2.03it/s]\n",
            "Epoch 11 - Validation loss: 0.2196035245474428, Accuracy=0.9341: 100%|██████████| 625/625 [02:36<00:00,  3.99it/s]\n",
            "Epoch 12 - Training loss: 0.17347364328439352, Accuracy=0.9454174664107485: 100%|██████████| 1563/1563 [12:51<00:00,  2.03it/s]\n",
            "Epoch 12 - Validation loss: 0.20078118690289556, Accuracy=0.937: 100%|██████████| 625/625 [02:37<00:00,  3.96it/s]\n",
            "Epoch 13 - Training loss: 0.1636921267977946, Accuracy=0.9481565898912349: 100%|██████████| 1563/1563 [13:02<00:00,  2.00it/s]\n",
            "Epoch 13 - Validation loss: 0.1807159510238096, Accuracy=0.8385:  89%|████████▉ | 559/625 [02:24<00:16,  3.89it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNhiHpgMtMTo"
      },
      "source": [
        "#LSTM on psMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjVjT5_Z8K3H",
        "outputId": "4c6ba9cf-9735-4a78-9b33-1010dede2842"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "\n",
        "model = LSTMModel().cuda()\n",
        "print(\"\\nnumber of paramaters : \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(\"\\n\\n\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model.train()\n",
        "print(model)\n",
        "dataset = torch.utils.data.TensorDataset(torch.Tensor(train_X[:50000]).cuda(), torch.Tensor(train_Y[:50000]).long().cuda())\n",
        "dataset = data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "dataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X[:10000]).cuda(), torch.Tensor(test_Y[:10000]).long().cuda())\n",
        "dataset_valid = data.DataLoader(dataset_valid, batch_size=16, shuffle=False)\n",
        "\n",
        "train(model, 40, dataset, dataset_valid)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3125 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "number of paramaters :  164410\n",
            "\n",
            "\n",
            "\n",
            "LSTMModel(\n",
            "  (LSTM): LSTM(1, 200, batch_first=True)\n",
            "  (dense): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 1.8835647461128235, Accuracy=0.3115: 100%|██████████| 3125/3125 [01:35<00:00, 32.65it/s]\n",
            "Epoch 0 - Validation loss: 1.5498540615081786, Accuracy=0.449: 100%|██████████| 625/625 [00:08<00:00, 76.27it/s]\n",
            "Epoch 1 - Training loss: 1.325026750278473, Accuracy=0.53338: 100%|██████████| 3125/3125 [01:39<00:00, 31.56it/s]\n",
            "Epoch 1 - Validation loss: 1.0926557548999787, Accuracy=0.6236: 100%|██████████| 625/625 [00:08<00:00, 75.12it/s]\n",
            "Epoch 2 - Training loss: 1.053787413930893, Accuracy=0.64094: 100%|██████████| 3125/3125 [01:37<00:00, 31.98it/s]\n",
            "Epoch 2 - Validation loss: 0.9416957238674164, Accuracy=0.6856: 100%|██████████| 625/625 [00:08<00:00, 75.72it/s]\n",
            "Epoch 3 - Training loss: 0.9011304340362549, Accuracy=0.69472: 100%|██████████| 3125/3125 [01:37<00:00, 32.09it/s]\n",
            "Epoch 3 - Validation loss: 0.8110850373029709, Accuracy=0.7323: 100%|██████████| 625/625 [00:08<00:00, 76.55it/s]\n",
            "Epoch 4 - Training loss: 0.8074525321483612, Accuracy=0.7316: 100%|██████████| 3125/3125 [01:37<00:00, 32.15it/s]\n",
            "Epoch 4 - Validation loss: 0.7398865075349808, Accuracy=0.7586: 100%|██████████| 625/625 [00:08<00:00, 76.21it/s]\n",
            "Epoch 5 - Training loss: 0.73463030066967, Accuracy=0.75676: 100%|██████████| 3125/3125 [01:37<00:00, 32.18it/s]\n",
            "Epoch 5 - Validation loss: 0.6697962532520294, Accuracy=0.7789: 100%|██████████| 625/625 [00:08<00:00, 76.24it/s]\n",
            "Epoch 6 - Training loss: 0.6789035224533081, Accuracy=0.77388: 100%|██████████| 3125/3125 [01:38<00:00, 31.65it/s]\n",
            "Epoch 6 - Validation loss: 0.6682044794917107, Accuracy=0.7787: 100%|██████████| 625/625 [00:08<00:00, 76.38it/s]\n",
            "Epoch 7 - Training loss: 0.6285938830280304, Accuracy=0.79178: 100%|██████████| 3125/3125 [01:37<00:00, 32.06it/s]\n",
            "Epoch 7 - Validation loss: 0.6015175049096346, Accuracy=0.8074: 100%|██████████| 625/625 [00:08<00:00, 76.31it/s]\n",
            "Epoch 8 - Training loss: 0.5811810309427977, Accuracy=0.81016: 100%|██████████| 3125/3125 [01:37<00:00, 32.18it/s]\n",
            "Epoch 8 - Validation loss: 0.5629640577465296, Accuracy=0.8197: 100%|██████████| 625/625 [00:08<00:00, 75.70it/s]\n",
            "Epoch 9 - Training loss: 0.5431085139292479, Accuracy=0.82402: 100%|██████████| 3125/3125 [01:37<00:00, 32.09it/s]\n",
            "Epoch 9 - Validation loss: 0.5408866026550532, Accuracy=0.8253: 100%|██████████| 625/625 [00:08<00:00, 76.00it/s]\n",
            "Epoch 10 - Training loss: 0.5069563075113297, Accuracy=0.83618: 100%|██████████| 3125/3125 [01:37<00:00, 32.12it/s]\n",
            "Epoch 10 - Validation loss: 0.5225335864290596, Accuracy=0.8335: 100%|██████████| 625/625 [00:08<00:00, 76.18it/s]\n",
            "Epoch 11 - Training loss: 0.4719612292802334, Accuracy=0.84578: 100%|██████████| 3125/3125 [01:36<00:00, 32.26it/s]\n",
            "Epoch 11 - Validation loss: 0.4704059818536043, Accuracy=0.8491: 100%|██████████| 625/625 [00:08<00:00, 76.08it/s]\n",
            "Epoch 12 - Training loss: 0.44243283003807066, Accuracy=0.85672: 100%|██████████| 3125/3125 [01:37<00:00, 32.09it/s]\n",
            "Epoch 12 - Validation loss: 0.43407566157653926, Accuracy=0.8658: 100%|██████████| 625/625 [00:08<00:00, 76.75it/s]\n",
            "Epoch 13 - Training loss: 0.42040838955283166, Accuracy=0.86518: 100%|██████████| 3125/3125 [01:37<00:00, 31.99it/s]\n",
            "Epoch 13 - Validation loss: 0.43748018431663516, Accuracy=0.8603: 100%|██████████| 625/625 [00:08<00:00, 76.30it/s]\n",
            "Epoch 14 - Training loss: 0.39956006661832333, Accuracy=0.87044: 100%|██████████| 3125/3125 [01:36<00:00, 32.22it/s]\n",
            "Epoch 14 - Validation loss: 0.4402349870316684, Accuracy=0.8622: 100%|██████████| 625/625 [00:08<00:00, 75.92it/s]\n",
            "Epoch 15 - Training loss: 0.37759324289798735, Accuracy=0.8783: 100%|██████████| 3125/3125 [01:37<00:00, 32.17it/s]\n",
            "Epoch 15 - Validation loss: 0.42258463695421816, Accuracy=0.8692: 100%|██████████| 625/625 [00:08<00:00, 76.40it/s]\n",
            "Epoch 16 - Training loss: 0.35876282393395903, Accuracy=0.88344: 100%|██████████| 3125/3125 [01:36<00:00, 32.26it/s]\n",
            "Epoch 16 - Validation loss: 0.40119710870310665, Accuracy=0.8762: 100%|██████████| 625/625 [00:08<00:00, 76.55it/s]\n",
            "Epoch 17 - Training loss: 0.3439259949772805, Accuracy=0.88758: 100%|██████████| 3125/3125 [01:37<00:00, 32.10it/s]\n",
            "Epoch 17 - Validation loss: 0.40356583215668795, Accuracy=0.872: 100%|██████████| 625/625 [00:08<00:00, 74.70it/s]\n",
            "Epoch 18 - Training loss: 0.3256662821006775, Accuracy=0.89334: 100%|██████████| 3125/3125 [01:37<00:00, 32.18it/s]\n",
            "Epoch 18 - Validation loss: 0.36376751109436156, Accuracy=0.8841: 100%|██████████| 625/625 [00:08<00:00, 76.16it/s]\n",
            "Epoch 19 - Training loss: 0.3099218481694162, Accuracy=0.89864: 100%|██████████| 3125/3125 [01:36<00:00, 32.25it/s]\n",
            "Epoch 19 - Validation loss: 0.388184348859638, Accuracy=0.8812: 100%|██████████| 625/625 [00:08<00:00, 76.80it/s]\n",
            "Epoch 20 - Training loss: 0.2938391384732723, Accuracy=0.90414: 100%|██████████| 3125/3125 [01:37<00:00, 31.90it/s]\n",
            "Epoch 20 - Validation loss: 0.3829008324407041, Accuracy=0.882: 100%|██████████| 625/625 [00:08<00:00, 76.47it/s]\n",
            "Epoch 21 - Training loss: 0.2793755875250697, Accuracy=0.9086: 100%|██████████| 3125/3125 [01:37<00:00, 32.13it/s]\n",
            "Epoch 21 - Validation loss: 0.43479842090904713, Accuracy=0.8705: 100%|██████████| 625/625 [00:08<00:00, 75.97it/s]\n",
            "Epoch 22 - Training loss: 0.27089799889177085, Accuracy=0.9117: 100%|██████████| 3125/3125 [01:37<00:00, 32.05it/s]\n",
            "Epoch 22 - Validation loss: 0.37294826541319487, Accuracy=0.8847: 100%|██████████| 625/625 [00:08<00:00, 76.02it/s]\n",
            "Epoch 23 - Training loss: 0.2562789867401123, Accuracy=0.9165: 100%|██████████| 3125/3125 [01:37<00:00, 32.16it/s]\n",
            "Epoch 23 - Validation loss: 0.3485809216279536, Accuracy=0.8912: 100%|██████████| 625/625 [00:08<00:00, 75.98it/s]\n",
            "Epoch 24 - Training loss: 0.24674499871388078, Accuracy=0.92018: 100%|██████████| 3125/3125 [01:37<00:00, 32.00it/s]\n",
            "Epoch 24 - Validation loss: 0.36913990581696854, Accuracy=0.8912: 100%|██████████| 625/625 [00:08<00:00, 74.78it/s]\n",
            "Epoch 25 - Training loss: 0.23258692306153475, Accuracy=0.92446: 100%|██████████| 3125/3125 [01:40<00:00, 31.04it/s]\n",
            "Epoch 25 - Validation loss: 0.36152131667733195, Accuracy=0.8904: 100%|██████████| 625/625 [00:08<00:00, 73.08it/s]\n",
            "Epoch 26 - Training loss: 0.22403170207545162, Accuracy=0.92614: 100%|██████████| 3125/3125 [01:39<00:00, 31.52it/s]\n",
            "Epoch 26 - Validation loss: 0.39023078832775354, Accuracy=0.8799: 100%|██████████| 625/625 [00:08<00:00, 72.92it/s]\n",
            "Epoch 27 - Training loss: 0.21664115564212202, Accuracy=0.92958: 100%|██████████| 3125/3125 [01:40<00:00, 31.12it/s]\n",
            "Epoch 27 - Validation loss: 0.37809513165634123, Accuracy=0.8905: 100%|██████████| 625/625 [00:08<00:00, 72.16it/s]\n",
            "Epoch 28 - Training loss: 0.2086730573157221, Accuracy=0.93126: 100%|██████████| 3125/3125 [01:38<00:00, 31.58it/s]\n",
            "Epoch 28 - Validation loss: 0.3495068477151915, Accuracy=0.8953: 100%|██████████| 625/625 [00:08<00:00, 74.65it/s]\n",
            "Epoch 29 - Training loss: 0.1977577785269916, Accuracy=0.93478: 100%|██████████| 3125/3125 [01:37<00:00, 31.96it/s]\n",
            "Epoch 29 - Validation loss: 0.3481817605799064, Accuracy=0.8979: 100%|██████████| 625/625 [00:08<00:00, 73.89it/s]\n",
            "Epoch 30 - Training loss: 0.19046487206634133, Accuracy=0.9359: 100%|██████████| 3125/3125 [01:38<00:00, 31.85it/s]\n",
            "Epoch 30 - Validation loss: 0.3635236283207312, Accuracy=0.8931: 100%|██████████| 625/625 [00:08<00:00, 74.58it/s]\n",
            "Epoch 31 - Training loss: 0.263782391304411, Accuracy=0.91354: 100%|██████████| 3125/3125 [01:38<00:00, 31.88it/s]\n",
            "Epoch 31 - Validation loss: 0.354839483162947, Accuracy=0.8961: 100%|██████████| 625/625 [00:08<00:00, 73.84it/s]\n",
            "Epoch 32 - Training loss: 0.16433469276387244, Accuracy=0.94608: 100%|██████████| 3125/3125 [01:37<00:00, 32.00it/s]\n",
            "Epoch 32 - Validation loss: 0.3754113071932457, Accuracy=0.8986: 100%|██████████| 625/625 [00:08<00:00, 74.74it/s]\n",
            "Epoch 33 - Training loss: 0.16809197701260448, Accuracy=0.9441: 100%|██████████| 3125/3125 [01:37<00:00, 31.97it/s]\n",
            "Epoch 33 - Validation loss: 0.3502211558893323, Accuracy=0.8968: 100%|██████████| 625/625 [00:08<00:00, 74.62it/s]\n",
            "Epoch 34 - Training loss: 0.17028297761045397, Accuracy=0.94304: 100%|██████████| 3125/3125 [01:38<00:00, 31.74it/s]\n",
            "Epoch 34 - Validation loss: 0.39565928608682005, Accuracy=0.8941: 100%|██████████| 625/625 [00:08<00:00, 75.17it/s]\n",
            "Epoch 35 - Training loss: 0.16457013004077597, Accuracy=0.94586: 100%|██████████| 3125/3125 [01:37<00:00, 32.01it/s]\n",
            "Epoch 35 - Validation loss: 0.39459532248796897, Accuracy=0.8933: 100%|██████████| 625/625 [00:08<00:00, 74.31it/s]\n",
            "Epoch 36 - Training loss: 0.15408659414365888, Accuracy=0.9483: 100%|██████████| 3125/3125 [01:37<00:00, 31.97it/s]\n",
            "Epoch 36 - Validation loss: 0.37659236865928397, Accuracy=0.8952: 100%|██████████| 625/625 [00:08<00:00, 75.17it/s]\n",
            "Epoch 37 - Training loss: 0.15616476024648174, Accuracy=0.94772: 100%|██████████| 3125/3125 [01:37<00:00, 32.05it/s]\n",
            "Epoch 37 - Validation loss: 0.36959271724447607, Accuracy=0.8942: 100%|██████████| 625/625 [00:08<00:00, 74.21it/s]\n",
            "Epoch 38 - Training loss: 0.1460296014567092, Accuracy=0.95156: 100%|██████████| 3125/3125 [01:37<00:00, 32.10it/s]\n",
            "Epoch 38 - Validation loss: 0.37587529094908384, Accuracy=0.9008: 100%|██████████| 625/625 [00:08<00:00, 75.68it/s]\n",
            "Epoch 39 - Training loss: 0.13876156042307616, Accuracy=0.9537: 100%|██████████| 3125/3125 [01:37<00:00, 32.02it/s]\n",
            "Epoch 39 - Validation loss: 0.3700341708094813, Accuracy=0.8978: 100%|██████████| 625/625 [00:08<00:00, 74.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrewADhoK9w1"
      },
      "source": [
        "PATH=\"lstm_trained_till_40\"\n",
        "torch.save(model, PATH)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}