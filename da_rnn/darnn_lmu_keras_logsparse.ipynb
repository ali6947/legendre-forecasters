{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darnn_lmu_keras_logsparse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashgupta-7/legendre-forecasters/blob/main/da_rnn/darnn_lmu_keras_logsparse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7EMTwrl7vJl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIOv-ZSbIkrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b1b980-65cc-4d16-c26a-4847414143f8"
      },
      "source": [
        " !git clone https://github.com/kaelzhang/DA-RNN-in-Tensorflow-2-and-PyTorch/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DA-RNN-in-Tensorflow-2-and-PyTorch'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Counting objects: 100% (256/256), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 256 (delta 127), reused 184 (delta 60), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (256/256), 7.64 MiB | 19.50 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9y3V66hVPx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a465f7-cbe5-4683-c180-f27ed80b6a0d"
      },
      "source": [
        "!git clone https://github.com/nengo/keras-lmu"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-lmu'...\n",
            "remote: Enumerating objects: 738, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 738 (delta 130), reused 162 (delta 73), pack-reused 510\u001b[K\n",
            "Receiving objects: 100% (738/738), 10.49 MiB | 13.51 MiB/s, done.\n",
            "Resolving deltas: 100% (377/377), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeA84aWPGWCI"
      },
      "source": [
        "# import keras_lmu"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmPjk0Sn4eUj",
        "outputId": "7b270ce8-757e-40e8-c8d4-d1aaeb57ff6c"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6FmAJXUxgzb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "import math\n",
        "#final\n",
        "np.random.seed(123)\n",
        "python_random.seed(123)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4udNOJrIs0b",
        "outputId": "a2ce10a7-94ca-4eac-de79-3f8a4bedd5ae"
      },
      "source": [
        "cd /content/DA-RNN-in-Tensorflow-2-and-PyTorch/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DA-RNN-in-Tensorflow-2-and-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t-RZDPEQRZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc61cdca-4b8b-4811-9c5f-0a60443ecd75"
      },
      "source": [
        "# !pip install keras_lmu\n",
        "!pip install get_rolling_window\n",
        "!ls /content/keras-lmu/keras_lmu/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting get_rolling_window\n",
            "  Downloading https://files.pythonhosted.org/packages/c5/52/a4a312e7d1595545843a04810fd4059b4267afc2eafd0e0cd073567e7524/get_rolling_window-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from get_rolling_window) (1.19.5)\n",
            "Installing collected packages: get-rolling-window\n",
            "Successfully installed get-rolling-window-1.0.0\n",
            "__init__.py  layers.py\ttests  version.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo29trKWG4b2"
      },
      "source": [
        "from typing import Optional\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import (\n",
        "    Layer,\n",
        "    LSTM,\n",
        "    Dense,\n",
        "    Permute\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from da_rnn.common import (\n",
        "    check_T\n",
        ")\n",
        "\n",
        "import os\n",
        "os.sys.path.insert(0, \"/content/keras-lmu/\")\n",
        "# from sibling import module\n",
        "import keras_lmu\n",
        "tf.random.set_seed(\n",
        "    42\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHyXmmZ3Ig5k"
      },
      "source": [
        "class InputAttention(Layer):\n",
        "    T: int\n",
        "\n",
        "    def __init__(self, T, **kwargs):\n",
        "\n",
        "        super().__init__(name='input_attention', **kwargs)\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.W_e = Dense(T)\n",
        "        self.U_e = Dense(T)\n",
        "        self.v_e = Dense(1)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_state,\n",
        "        cell_state,\n",
        "        X\n",
        "    ):\n",
        "\n",
        "        n = X.shape[2]\n",
        "\n",
        "        # [h_t-1; s_t-1]\n",
        "        hs = K.repeat(\n",
        "            tf.concat([hidden_state, cell_state], axis=-1),\n",
        "            # -> (batch_size, m * 2); (batch_size, m+d) if LMU\n",
        "            n\n",
        "        )\n",
        "        # -> (batch_size, n, m * 2); (batch_size, n, m + d) if LMU\n",
        "\n",
        "        tanh = tf.math.tanh(\n",
        "            tf.concat([\n",
        "                self.W_e(hs),\n",
        "                # -> (batch_size, n, T)\n",
        "\n",
        "                self.U_e(\n",
        "                    Permute((2, 1))(X)\n",
        "                    # -> (batch_size, n, T)\n",
        "                ),\n",
        "                # -> (batch_size, n, T)\n",
        "            ], axis=-1)\n",
        "            # -> (batch_size, n, T * 2)\n",
        "        )\n",
        "        # -> (batch_size, n, T * 2)\n",
        "\n",
        "        # Equation 8:\n",
        "        e = self.v_e(tanh)\n",
        "        # -> (batch_size, n, 1)\n",
        "\n",
        "        # Equation: 9\n",
        "        return tf.nn.softmax(\n",
        "            Permute((2, 1))(e)\n",
        "            # -> (batch_size, 1, n)\n",
        "        )\n",
        "        # -> (batch_size, 1, n)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjnm5mTU3zsS"
      },
      "source": [
        "# !pip uninstall keras_lmu"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCd2Dl_g4kIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c7a26f-c77a-4dc4-df32-6e962e55421f"
      },
      "source": [
        "import keras_lmu\n",
        "# import gputil\n",
        "import tensorflow as tf \n",
        "if tf.test.gpu_device_name(): \n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz0hnAhRmwrp"
      },
      "source": [
        " def log_mask( win_len, sub_len):\n",
        "        mask = np.zeros((win_len, win_len))\n",
        "        for i in range(win_len):\n",
        "            mask[i] = row_mask(i, sub_len, win_len)\n",
        "        return mask\n",
        "\n",
        "def row_mask( index, sub_len, win_len):\n",
        "    \n",
        "    log_l = math.ceil(np.log2(sub_len))\n",
        "    mask = np.zeros((win_len))\n",
        "    if((win_len // sub_len) * 2 * (log_l) > index):\n",
        "        mask[:(index + 1)] = 1\n",
        "    else:\n",
        "        while(index >= 0):\n",
        "            if((index - log_l + 1) < 0):\n",
        "                mask[:index] = 1\n",
        "                break\n",
        "            mask[index - log_l + 1:(index + 1)] = 1  # Local attention\n",
        "            for i in range(0, log_l):\n",
        "                new_index = index - log_l + 1 - 2**i\n",
        "                if((index - new_index) <= sub_len and new_index >= 0):\n",
        "                    mask[new_index] = 1\n",
        "            index -= sub_len\n",
        "    return mask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdettCssyMUH"
      },
      "source": [
        "def get_temporal_mask(win_len,sub_len): #win_len=T\n",
        "  a=log_mask(win_len,sub_len)\n",
        "  # print(a)\n",
        "  b = a+np.flipud(np.fliplr(a))-np.eye(win_len)\n",
        "  # np.fill_diagonal(b, 1)\n",
        "  return b #np.transpose(a) \n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZnAdSmCI-lB"
      },
      "source": [
        "class Encoder(Layer):\n",
        "    T: int\n",
        "    m: int\n",
        "    d: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        d: int,\n",
        "        lmu=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "\n",
        "        super().__init__(name='encoder_input', **kwargs)\n",
        "\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.lmu = lmu\n",
        "        #n_embed + n_\n",
        "        if not lmu:\n",
        "            assert(m==d)\n",
        "\n",
        "        if self.lmu:\n",
        "          self.input_lstm = keras_lmu.LMUCell(memory_d=self.d, order=self.d, theta=self.T, #LMU\n",
        "                hidden_cell = tf.keras.layers.SimpleRNNCell(m), # m -> \tPositive integer, dimensionality of the output space.\n",
        "                hidden_to_memory=False,\n",
        "                memory_to_memory=False,\n",
        "                input_to_hidden=True,\n",
        "                kernel_initializer=\"ones\",\n",
        "               #return_sequences = False\n",
        "            )\n",
        "        else:\n",
        "          self.input_lstm = LSTM(m, return_state=True)\n",
        "        self.input_attention = InputAttention(T)\n",
        "\n",
        "    def call(self, X) -> tf.Tensor:\n",
        "\n",
        "        batch_size = K.shape(X)[0]\n",
        "\n",
        "        hidden_state = tf.zeros((batch_size, self.m))\n",
        "        if self.lmu:\n",
        "          # print('lmuuu')\n",
        "          cell_state = tf.zeros((batch_size, self.d*self.d))\n",
        "        else:\n",
        "          cell_state = tf.zeros((batch_size, self.m))\n",
        "\n",
        "        X_encoded = []\n",
        "\n",
        "        for t in range(self.T):\n",
        "            # print(t)\n",
        "            Alpha_t = self.input_attention(hidden_state, cell_state, X)\n",
        "            # print('hello prat')\n",
        "            # print(Alpha_t.shape)\n",
        "            # print(X[:, None, t, :].shape)\n",
        "            # Equation 10\n",
        "            X_tilde_t = tf.multiply(\n",
        "                Alpha_t,\n",
        "                # TODO:\n",
        "                # make sure it can share the underlying data\n",
        "                X[:, None, t, :]\n",
        "            )\n",
        "            # -> (batch_size, 1, n)\n",
        "\n",
        "            # Equation 11\n",
        "            # print(\"Xtilde\", X_tilde_t.shape, \"Hidden\", hidden_state.shape, \"Mem\", cell_state.shape)\n",
        "            \n",
        "            if self.lmu:\n",
        "              X_tilde_t = X_tilde_t[:, 0, :]\n",
        "              # print(\"Xtilde\", X_tilde_t.shape)\n",
        "              # print(\"Out\", self.input_lstm(X_tilde_t,states = [hidden_state, cell_state])[0].shape)\n",
        "              _ , final_state = self.input_lstm(X_tilde_t,\n",
        "              states = [hidden_state, cell_state])\n",
        "              \n",
        "              hidden_state = final_state[0]\n",
        "              cell_state = final_state[-1]\n",
        "            else:\n",
        "              hidden_state, _, cell_state = self.input_lstm(\n",
        "                X_tilde_t,\n",
        "                initial_state=[hidden_state, cell_state]\n",
        "            )\n",
        "\n",
        "            X_encoded.append(\n",
        "                hidden_state[:, None, :]\n",
        "                # -> (batch_size, 1, m)\n",
        "            )\n",
        "\n",
        "        return tf.concat(X_encoded, axis=1)\n",
        "        # -> (batch_size, T, m)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'd': self.d\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "301L6e2BJBK8"
      },
      "source": [
        "class TemporalAttention(Layer):\n",
        "    m: int\n",
        "\n",
        "    def __init__(self, m: int, **kwargs):\n",
        "\n",
        "        super().__init__(name='temporal_attention', **kwargs)\n",
        "        \n",
        "        self.m = m\n",
        "\n",
        "        self.W_d = Dense(m)\n",
        "        self.U_d = Dense(m)\n",
        "        self.v_d = Dense(1)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_state,\n",
        "        cell_state,\n",
        "        X_encoded\n",
        "    ):\n",
        "\n",
        "        # Equation 12\n",
        "        l = self.v_d(\n",
        "            tf.math.tanh(\n",
        "                tf.concat([\n",
        "                    self.W_d(\n",
        "                        K.repeat(\n",
        "                            tf.concat([hidden_state, cell_state], axis=-1),\n",
        "                            # -> (batch_size, p * 2)\n",
        "                            X_encoded.shape[1]\n",
        "                        )\n",
        "                        # -> (batch_size, T, p * 2)\n",
        "                    ),\n",
        "                    # -> (batch_size, T, m)\n",
        "                    self.U_d(X_encoded)\n",
        "                ], axis=-1)\n",
        "                # -> (batch_size, T, m * 2)\n",
        "            )\n",
        "            # -> (batch_size, T, m)\n",
        "        )\n",
        "        # -> (batch_size, T, 1)\n",
        "\n",
        "        # Equation 13\n",
        "        return tf.nn.softmax(l, axis=1)\n",
        "        # -> (batch_size, T, 1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'm': self.m\n",
        "        })\n",
        "        return config\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMlyRbG77EPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d0adf8-04e6-48f9-c9a8-6c204bccce6b"
      },
      "source": [
        "a=tf.convert_to_tensor(get_temporal_mask(12,20),dtype=tf.float32)\n",
        "print(a) #[:,49]\n",
        "\n",
        "print(tf.multiply(-a[None,:,49:50],a[None,:,49:50]))\n",
        "print(tf.multiply(-a[None,:,49:50],a[None,:,49:50]).shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
            " [1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            " [0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            " [0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.]], shape=(12, 12), dtype=float32)\n",
            "tf.Tensor([], shape=(1, 12, 0), dtype=float32)\n",
            "(1, 12, 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UdhSoJpJD3_"
      },
      "source": [
        "class Decoder(Layer):\n",
        "    T: int\n",
        "    m: int\n",
        "    p: int\n",
        "    d: int\n",
        "    y_dim: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        p: int,\n",
        "        d: int,\n",
        "        y_dim: int,\n",
        "        lmu=False,\n",
        "         **kwargs\n",
        "    ):\n",
        "\n",
        "        super().__init__(name='decoder', **kwargs)\n",
        "        self.log_mask = tf.convert_to_tensor(get_temporal_mask(T,20),dtype=tf.float32)\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.p = p\n",
        "        self.d = d\n",
        "        self.lmu = lmu\n",
        "        self.y_dim = y_dim\n",
        "\n",
        "        self.temp_attention = TemporalAttention(m)\n",
        "        self.dense = Dense(1)\n",
        "        if not lmu:\n",
        "            assert(p==d)\n",
        "        \n",
        "        if self.lmu:\n",
        "          # print('hello')\n",
        "          self.decoder_lstm = keras_lmu.LMUCell(memory_d=self.d, order=self.d, theta=self.T, #LMU\n",
        "                hidden_cell = tf.keras.layers.SimpleRNNCell(p), # m -> \tPositive integer, dimensionality of the output space.\n",
        "                hidden_to_memory=False,\n",
        "                memory_to_memory=False,\n",
        "                input_to_hidden=True,\n",
        "                kernel_initializer=\"ones\",\n",
        "               #return_sequences = False\n",
        "            )\n",
        "        else:\n",
        "          self.decoder_lstm = LSTM(p, return_state=True)\n",
        "\n",
        "        self.Wb = Dense(p)\n",
        "        self.vb = Dense(y_dim)\n",
        "\n",
        "    def call(self, Y, X_encoded) -> tf.Tensor:\n",
        "\n",
        "        batch_size = K.shape(X_encoded)[0]\n",
        "        hidden_state = tf.zeros((batch_size, self.p))\n",
        "        if self.lmu:\n",
        "          cell_state = tf.zeros((batch_size, self.d*self.d))\n",
        "        else:\n",
        "          cell_state = tf.zeros((batch_size, self.p))\n",
        "\n",
        "        # c in the paper\n",
        "        context_vector = tf.zeros((batch_size, 1, self.m))\n",
        "        # -> (batch_size, 1, m)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            # print('de'+str(t))\n",
        "            Beta_t = self.temp_attention(\n",
        "                hidden_state,\n",
        "                cell_state,\n",
        "                X_encoded\n",
        "            )\n",
        "            # -> (batch_size, T, 1)\n",
        "\n",
        "            # Equation 14\n",
        "            context_vector = tf.matmul(\n",
        "                #Beta_t, X_encoded, transpose_a=True\n",
        "                 tf.multiply(Beta_t,self.log_mask[None,:,t:t+1]), X_encoded, transpose_a=True\n",
        "            )\n",
        "            # print('hello sp')\n",
        "            # print(Beta_t.shape,end='**\\n')\n",
        "            # print(X_encoded.shape,end='**\\n')\n",
        "            # -> (batch_size, 1, m)\n",
        "\n",
        "            # Equation 15\n",
        "            y_tilde = self.dense(\n",
        "                tf.concat([Y[:, None, t, :], context_vector], axis=-1)\n",
        "                # -> (batch_size, 1, y_dim + m)\n",
        "            )\n",
        "            # -> (batch_size, 1, 1)\n",
        "\n",
        "            # Equation 16\n",
        "            if self.lmu:\n",
        "              y_tilde = y_tilde[:, 0, :]\n",
        "              _ , final_state = self.decoder_lstm(y_tilde,\n",
        "              states = [hidden_state, cell_state])\n",
        "              \n",
        "              hidden_state = final_state[0]\n",
        "              cell_state = final_state[-1]\n",
        "            else:\n",
        "              hidden_state, _, cell_state = self.decoder_lstm(\n",
        "                  y_tilde,\n",
        "                  initial_state=[hidden_state, cell_state]\n",
        "              )\n",
        "            # -> (batch_size, p)\n",
        "\n",
        "        concatenated = tf.concat(\n",
        "            [hidden_state[:, None, :], context_vector], axis=-1\n",
        "        )\n",
        "        # -> (batch_size, 1, m + p)\n",
        "\n",
        "        # Equation 22\n",
        "        y_hat_T = self.vb(\n",
        "            self.Wb(concatenated)\n",
        "            # -> (batch_size, 1, p)\n",
        "        )\n",
        "        # -> (batch_size, 1, y_dim)\n",
        "        # print('crax')\n",
        "        return tf.squeeze(y_hat_T, axis=1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'p': self.p,\n",
        "            'y_dim': self.y_dim\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FVwxhHJH8R"
      },
      "source": [
        "class DARNN(Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        d: int,\n",
        "        p: Optional[int] = None,\n",
        "        y_dim: int = 1,\n",
        "        lmu=False\n",
        "    ):\n",
        "\n",
        "        super().__init__(name='DARNN')\n",
        "\n",
        "        check_T(T)\n",
        "\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.p = p or m\n",
        "        self.y_dim = y_dim\n",
        "        self.lmu = lmu\n",
        "\n",
        "        self.encoder = Encoder(T, m, d=self.d, lmu=self.lmu)\n",
        "        self.decoder = Decoder(T, m, p, d=self.d, lmu=self.lmu, y_dim=y_dim)\n",
        "\n",
        "    # Equation 1\n",
        "    def call(self, inputs):\n",
        "        # print('here')\n",
        "        X = inputs[:, :, :-self.y_dim]\n",
        "        # -> (batch_size, T, n)\n",
        "\n",
        "        # Y's window size is one less than X's\n",
        "        # so, abandon `y_T`\n",
        "\n",
        "        # By doing this, there are some benefits which makes it pretty easy to\n",
        "        # process datasets\n",
        "        Y = inputs[:, :, -self.y_dim:]\n",
        "        # -> (batch_size, T - 1, y_dim)\n",
        "\n",
        "        X_encoded = self.encoder(X)\n",
        "        # print('koool')\n",
        "        y_hat_T = self.decoder(Y, X_encoded)\n",
        "        # -> (batch_size, y_dim)\n",
        "\n",
        "        return y_hat_T\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'p': self.p,\n",
        "            'd': self.d,\n",
        "            'y_dim': self.y_dim\n",
        "        }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmB4dzMOJSrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457ff6f1-54ec-4d5c-9b99-fa4e84e744e3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UzkBzVWJ8Dn"
      },
      "source": [
        "dataroot = '/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C3haGE5KB4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f63d9e9-2d74-4e37-fa74-2630b5563057"
      },
      "source": [
        "!ls '/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZn_ZT1qKQi1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(input_path, debug=True): \n",
        "\n",
        "    df = pd.read_csv(input_path, nrows=32*10 if debug else None)\n",
        "    X = df.loc[:, [x for x in df.columns.tolist()]].to_numpy() \n",
        "    return X"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcWL2v1PMKzf"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "features = read_data(dataroot, debug=False)\n",
        "scale = StandardScaler().fit(features)\n",
        "features = scale.transform(features)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01TQtQW8R5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16bda49f-d215-4338-8c6c-bad8f55d46f1"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40560, 82)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rMtELNCSssC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f266134-c261-4928-a35c-05f7a5609181"
      },
      "source": [
        "features"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.82166581, -3.42991957, -1.60918711, ..., -1.86674079,\n",
              "        -2.14183171, -2.35353513],\n",
              "       [-0.83220311, -3.40824969, -1.60918711, ..., -1.81032478,\n",
              "        -2.06400103, -2.35353513],\n",
              "       [-0.83792335, -3.3938031 , -1.66989855, ..., -1.70183245,\n",
              "        -2.05801406, -2.34133626],\n",
              "       ...,\n",
              "       [ 1.87717227,  1.16289176,  0.06697655, ...,  3.04774477,\n",
              "        -1.84344086,  1.7048016 ],\n",
              "       [ 1.88362367,  1.1737267 ,  0.07753506, ...,  3.0501316 ,\n",
              "        -1.84547643,  1.72163035],\n",
              "       [ 1.88362367,  1.17131893,  0.0722558 , ...,  3.05447129,\n",
              "        -1.84248294,  1.72151974]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADDhTHffNNmD"
      },
      "source": [
        "# !pip install get-rolling-window\n",
        "BATCH_SIZE = 256\n",
        "WINDOW_SIZE = 10\n",
        "ENCODER_HIDDEN_STATES = 128\n",
        "DECODER_HIDDEN_STATES = 128\n",
        "\n",
        "Y_DIM = 1\n",
        "\n",
        "DATA = 'nasdaq100_padding.csv'\n",
        "\n",
        "VALIDATION_RATIO = 0.2\n",
        "\n",
        "EPOCHS = 30"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD3Sy1GoMoao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f6dcb1-e106-4d48-a1c2-83c4bd570fb4"
      },
      "source": [
        "def get_labels_from_features(features):\n",
        "    return features[WINDOW_SIZE - 1:, -Y_DIM:][:, None, :]\n",
        "\n",
        "\n",
        "def split_by_ratio(features):\n",
        "    length = len(features)\n",
        "    train_length = 35100\n",
        "    validation_length = 2730 #int(VALIDATION_RATIO * length)\n",
        "    test_length = 2730\n",
        "    \n",
        "    return features[:train_length], features[train_length:train_length + validation_length], features[train_length + validation_length:train_length + validation_length + test_length] #features[:-validation_length], features[-validation_length:]\n",
        "\n",
        "\n",
        "training_features, validation_features, testing_features = split_by_ratio(features)\n",
        "\n",
        "print('training length', len(training_features))\n",
        "print('validation length', len(validation_features))\n",
        "print('testing length', len(testing_features))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training length 35100\n",
            "validation length 2730\n",
            "testing length 2730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71TAsnZM2oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57b4737-ef29-4ad8-9a2d-ad220a93100d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from get_rolling_window import rolling_window\n",
        "\n",
        "train_f, train_l = rolling_window(training_features, WINDOW_SIZE, 1), get_labels_from_features(training_features)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_f, train_l)).batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "print(train_f.shape, train_l.shape)\n",
        "\n",
        "val_f, val_l = rolling_window(validation_features, WINDOW_SIZE, 1), get_labels_from_features(validation_features)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_f, val_l)).batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "test_f, test_l = rolling_window(testing_features, WINDOW_SIZE, 1), get_labels_from_features(testing_features)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_f, test_l)).batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "train_ds"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35051, 50, 82) (35051, 1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 50, 82), (None, 1, 1)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyy-5S-2NlqL"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "model = DARNN(\n",
        "    T = WINDOW_SIZE,\n",
        "    m = ENCODER_HIDDEN_STATES,\n",
        "    d = ENCODER_HIDDEN_STATES,\n",
        "    p = DECODER_HIDDEN_STATES,\n",
        "    y_dim = Y_DIM,\n",
        "    lmu = False,\n",
        "    \n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mape']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0iDqj5NmuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86a0ffe-d484-4b1a-b675-6a5458e41494"
      },
      "source": [
        "feature_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "print('feature, label shape', feature_batch.shape, label_batch.shape)\n",
        "\n",
        "print('prediction shape', model(feature_batch).shape)\n",
        "\n",
        "model(feature_batch[:1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature, label shape (256, 50, 82) (256, 1, 1)\n",
            "prediction shape (256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.00524321]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlDGB2IWNqlz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d353384d-e270-47c3-c05f-4c239b679445"
      },
      "source": [
        "save_to = './ckpt_darnn_lstm_logsparse.hdf5'\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[\n",
        "        # Save checkpoints on best validation loss\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            save_to,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Stop early if the model overfits\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    ],\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "137/137 [==============================] - 216s 631ms/step - loss: 0.6321 - mae: 0.5408 - mape: 289.2203 - val_loss: 0.0299 - val_mae: 0.1394 - val_mape: 27.7185\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02988, saving model to ./ckpt_darnn_lstm_logsparse.hdf5\n",
            "Epoch 2/50\n",
            "137/137 [==============================] - 53s 389ms/step - loss: 0.0176 - mae: 0.0892 - mape: 34.5479 - val_loss: 0.0123 - val_mae: 0.0949 - val_mape: 14.1987\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02988 to 0.01231, saving model to ./ckpt_darnn_lstm_logsparse.hdf5\n",
            "Epoch 3/50\n",
            "137/137 [==============================] - 53s 388ms/step - loss: 0.0138 - mae: 0.0805 - mape: 35.8417 - val_loss: 0.0067 - val_mae: 0.0640 - val_mape: 10.8855\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01231 to 0.00666, saving model to ./ckpt_darnn_lstm_logsparse.hdf5\n",
            "Epoch 4/50\n",
            "137/137 [==============================] - 53s 388ms/step - loss: 0.0053 - mae: 0.0560 - mape: 34.8701 - val_loss: 0.0047 - val_mae: 0.0543 - val_mape: 9.2522\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00666 to 0.00473, saving model to ./ckpt_darnn_lstm_logsparse.hdf5\n",
            "Epoch 5/50\n",
            "137/137 [==============================] - 53s 388ms/step - loss: 0.0049 - mae: 0.0537 - mape: 33.1264 - val_loss: 0.0026 - val_mae: 0.0378 - val_mape: 6.6003\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00473 to 0.00258, saving model to ./ckpt_darnn_lstm_logsparse.hdf5\n",
            "Epoch 6/50\n",
            "137/137 [==============================] - 53s 388ms/step - loss: 0.0071 - mae: 0.0641 - mape: 37.9203 - val_loss: 0.0047 - val_mae: 0.0571 - val_mape: 10.8760\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00258\n",
            "Epoch 7/50\n",
            "137/137 [==============================] - 53s 388ms/step - loss: 0.0173 - mae: 0.1049 - mape: 59.1981 - val_loss: 0.0043 - val_mae: 0.0527 - val_mape: 9.0573\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00258\n",
            "Epoch 8/50\n",
            "137/137 [==============================] - 53s 389ms/step - loss: 0.0274 - mae: 0.1282 - mape: 62.6455 - val_loss: 0.0038 - val_mae: 0.0490 - val_mape: 8.6662\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00258\n",
            "Epoch 9/50\n",
            "137/137 [==============================] - 53s 389ms/step - loss: 0.0160 - mae: 0.0929 - mape: 52.2403 - val_loss: 0.0200 - val_mae: 0.1245 - val_mape: 19.5126\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00258\n",
            "Epoch 10/50\n",
            "137/137 [==============================] - 53s 389ms/step - loss: 0.0474 - mae: 0.1587 - mape: 82.5091 - val_loss: 0.0907 - val_mae: 0.2540 - val_mape: 42.5386\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00258\n",
            "Epoch 11/50\n",
            "137/137 [==============================] - 54s 390ms/step - loss: 0.0788 - mae: 0.2088 - mape: 131.4926 - val_loss: 0.0149 - val_mae: 0.1075 - val_mape: 16.4008\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00258\n",
            "Epoch 12/50\n",
            " 81/137 [================>.............] - ETA: 20s - loss: 0.0250 - mae: 0.1260 - mape: 62.8532"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-42692fd91f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     ],\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xHIejDZrOMC"
      },
      "source": [
        "results = model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7h786sms88c"
      },
      "source": [
        "preds = model.predict(test_ds)\n",
        "preds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QanfK4CDo52e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['loss'], label='MSE')\n",
        "# plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(preds, label='Predicted')\n",
        "plt.plot(test_l[:, 0, :], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "plt.close(fig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFolXFrON218"
      },
      "source": [
        "model.count_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJLmHncST_cO"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrgs8HY1Ia6v"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(keras_lmu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p71pbnfgAdQQ"
      },
      "source": [
        "model_lmu = DARNN(\n",
        "    T = WINDOW_SIZE,\n",
        "    m = ENCODER_HIDDEN_STATES,\n",
        "    d = 4,\n",
        "    p = DECODER_HIDDEN_STATES,\n",
        "    y_dim = Y_DIM,\n",
        "    lmu = True\n",
        ")\n",
        "\n",
        "model_lmu.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mape']\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tn7rvPqAnsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4906b196-ed7f-4c93-c297-0007e3274a02"
      },
      "source": [
        "feature_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "print('feature, label shape', feature_batch.shape, label_batch.shape)\n",
        "\n",
        "print('prediction shape', model_lmu(feature_batch).shape)\n",
        "\n",
        "model_lmu(feature_batch[:1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature, label shape (256, 50, 82) (256, 1, 1)\n",
            "prediction shape (256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.37261593]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFo1NMAiMnt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "640c5bad-e6ab-4d68-cc65-922808a3ebb5"
      },
      "source": [
        "save_to = './ckpt_darnn_lmu.hdf5'\n",
        "\n",
        "history = model_lmu.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[\n",
        "        # Save checkpoints on best validation loss\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            save_to,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Stop early if the model overfits\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    ],\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 13/137 [=>............................] - ETA: 35s - loss: 0.0042 - mae: 0.0481 - mape: 3.4486"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8223cc752303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     ],\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lw5upbKwHYe"
      },
      "source": [
        "results = model_lmu.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQrKWK5wJGI"
      },
      "source": [
        "preds = model_lmu.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvk8HH3WwV60"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(history.history['loss'], label='MSE')\n",
        "# plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(preds, label='Predicted')\n",
        "plt.plot(test_l[:, 0, :], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}