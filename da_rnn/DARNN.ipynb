{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DARNN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOa+L/NJY0DoJjFWlcvde40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "661fbcd29c314cbb84d623b3f1b5de80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dee2cb41b7404742aea674c8d0a81298",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_676d93d9305c470785b252500341f51d",
              "IPY_MODEL_a1dba9600f864f3795a479da6d761ec2"
            ]
          }
        },
        "dee2cb41b7404742aea674c8d0a81298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "676d93d9305c470785b252500341f51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce15f63ec8d94ddab7d643daa25f5759",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_623633d8cab140ea81be7ddb15545249"
          }
        },
        "a1dba9600f864f3795a479da6d761ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a43b29b7369a42b298de59cee27c37a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/50 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ccc19839b1a4552b439382802f76a4e"
          }
        },
        "ce15f63ec8d94ddab7d643daa25f5759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "623633d8cab140ea81be7ddb15545249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a43b29b7369a42b298de59cee27c37a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ccc19839b1a4552b439382802f76a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60ececb80395486f80146f7fab5e57b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c5ee229a7f8487597aa114bfb534855",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc1eaecb482343d098ab7e959674d7ca",
              "IPY_MODEL_9e0947b4c4ec4df99a224517f5e1c753"
            ]
          }
        },
        "7c5ee229a7f8487597aa114bfb534855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc1eaecb482343d098ab7e959674d7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3e001f9d52e43dd88aeb32fc3a303a7",
            "_dom_classes": [],
            "description": " 23%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 222,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6249147f9efe468686eb8001249f5ce4"
          }
        },
        "9e0947b4c4ec4df99a224517f5e1c753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf1b3dacd54d42448a65a36f33894401",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51/222 [01:26&lt;04:47,  1.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6223ef43380540f89f420fe7daedad49"
          }
        },
        "c3e001f9d52e43dd88aeb32fc3a303a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6249147f9efe468686eb8001249f5ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf1b3dacd54d42448a65a36f33894401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6223ef43380540f89f420fe7daedad49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashgupta-7/legendre-forecasters/blob/main/da_rnn/DARNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRNioL92hN2i",
        "outputId": "23ddad80-3617-4610-9ee5-8ad4521995f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubvqfMq7i0qg",
        "outputId": "c8976fe1-4781-4e87-9253-2754d88ef456"
      },
      "source": [
        "cd drive/My\\ Drive/aml_project"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/aml_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TRL26ydjEbS",
        "outputId": "b87620d8-6b59-4b2f-e20e-06c9d57b2f7d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.png  2.png  3.png  data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahTcSBRUjGCU"
      },
      "source": [
        "dataroot = 'data/nasdaq100_padding.csv'\n",
        "batchsize = 128\n",
        "nhidden_encoder = 128\n",
        "nhidden_decoder = 128\n",
        "ntimestep = 10\n",
        "lr = 0.001\n",
        "epochs = 50"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ub2NKmFjNHF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"encoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T,\n",
        "                 input_size,\n",
        "                 encoder_num_hidden,\n",
        "                 parallel=False):\n",
        "        \"\"\"Initialize an encoder in DA_RNN.\"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.input_size = input_size\n",
        "        self.parallel = parallel\n",
        "        self.T = T\n",
        "\n",
        "        # Fig 1. Temporal Attention Mechanism: Encoder is LSTM\n",
        "        self.encoder_lstm = nn.LSTM(\n",
        "            input_size=self.input_size,\n",
        "            hidden_size=self.encoder_num_hidden,\n",
        "            num_layers = 1\n",
        "        )\n",
        "\n",
        "        # Construct Input Attention Mechanism via deterministic attention model\n",
        "        # Eq. 8: W_e[h_{t-1}; s_{t-1}] + U_e * x^k\n",
        "        self.encoder_attn = nn.Linear(\n",
        "            in_features=2 * self.encoder_num_hidden + self.T - 1,\n",
        "            out_features=1\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"forward.\n",
        "\n",
        "        Args:\n",
        "            X: input data\n",
        "\n",
        "        \"\"\"\n",
        "        X_tilde = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.input_size).zero_())\n",
        "        X_encoded = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.encoder_num_hidden).zero_())\n",
        "\n",
        "        # Eq. 8, parameters not in nn.Linear but to be learnt\n",
        "        # v_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.input_size, self.T).uniform_(0, 1), requires_grad=True)\n",
        "        # U_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.T, self.T).uniform_(0, 1), requires_grad=True)\n",
        "\n",
        "        # h_n, s_n: initial states with dimention hidden_size\n",
        "        h_n = self._init_states(X)\n",
        "        s_n = self._init_states(X)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            # batch_size * input_size * (2 * hidden_size + T - 1)\n",
        "            x = torch.cat((h_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           s_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           X.permute(0, 2, 1)), dim=2)\n",
        "\n",
        "            x = self.encoder_attn(\n",
        "                x.view(-1, self.encoder_num_hidden * 2 + self.T - 1))\n",
        "\n",
        "            # get weights by softmax\n",
        "            alpha = F.softmax(x.view(-1, self.input_size))\n",
        "\n",
        "            # get new input for LSTM\n",
        "            x_tilde = torch.mul(alpha, X[:, t, :])\n",
        "\n",
        "            # Fix the warning about non-contiguous memory\n",
        "            # https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
        "            # self.encoder_lstm.flatten_parameters()\n",
        "\n",
        "            # encoder LSTM\n",
        "            _, final_state = self.encoder_lstm(x_tilde.unsqueeze(0), (h_n, s_n))\n",
        "            h_n = final_state[0]\n",
        "            s_n = final_state[1]\n",
        "\n",
        "            X_tilde[:, t, :] = x_tilde\n",
        "            X_encoded[:, t, :] = h_n\n",
        "\n",
        "        return X_tilde, X_encoded\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "        \"\"\"\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.encoder_num_hidden).zero_())\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"decoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T, decoder_num_hidden, encoder_num_hidden):\n",
        "        \"\"\"Initialize a decoder in DA_RNN.\"\"\"\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.T = T\n",
        "\n",
        "        self.attn_layer = nn.Sequential(\n",
        "            nn.Linear(2 * decoder_num_hidden + encoder_num_hidden, encoder_num_hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(encoder_num_hidden, 1)\n",
        "        )\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=1,\n",
        "            hidden_size=decoder_num_hidden\n",
        "        )\n",
        "        self.fc = nn.Linear(encoder_num_hidden + 1, 1)\n",
        "        self.fc_final = nn.Linear(decoder_num_hidden + encoder_num_hidden, 1)\n",
        "\n",
        "        self.fc.weight.data.normal_()\n",
        "\n",
        "    def forward(self, X_encoded, y_prev):\n",
        "        \"\"\"forward.\"\"\"\n",
        "        d_n = self._init_states(X_encoded)\n",
        "        c_n = self._init_states(X_encoded)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "\n",
        "            x = torch.cat((d_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           c_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           X_encoded), dim=2)\n",
        "\n",
        "            beta = F.softmax(self.attn_layer(\n",
        "                x.view(-1, 2 * self.decoder_num_hidden + self.encoder_num_hidden)).view(-1, self.T - 1))\n",
        "\n",
        "            # Eqn. 14: compute context vector\n",
        "            # batch_size * encoder_hidden_size\n",
        "            context = torch.bmm(beta.unsqueeze(1), X_encoded)[:, 0, :]\n",
        "            if t < self.T - 1:\n",
        "                # Eqn. 15\n",
        "                # batch_size * 1\n",
        "                y_tilde = self.fc(\n",
        "                    torch.cat((context, y_prev[:, t].unsqueeze(1)), dim=1))\n",
        "\n",
        "                # Eqn. 16: LSTM\n",
        "                # self.lstm_layer.flatten_parameters()\n",
        "                _, final_states = self.lstm_layer(\n",
        "                    y_tilde.unsqueeze(0), (d_n, c_n))\n",
        "\n",
        "                d_n = final_states[0]  # 1 * batch_size * decoder_num_hidden\n",
        "                c_n = final_states[1]  # 1 * batch_size * decoder_num_hidden\n",
        "\n",
        "        # Eqn. 22: final output\n",
        "        y_pred = self.fc_final(torch.cat((d_n[0], context), dim=1))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def _init_states(self, X):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "\n",
        "        \"\"\"\n",
        "        # hidden state and cell state [num_layers*num_directions, batch_size, hidden_size]\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), self.decoder_num_hidden).zero_())\n",
        "\n",
        "\n",
        "class DA_rnn(nn.Module):\n",
        "    \"\"\"da_rnn.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y, T,\n",
        "                 encoder_num_hidden,\n",
        "                 decoder_num_hidden,\n",
        "                 batch_size,\n",
        "                 learning_rate,\n",
        "                 epochs,\n",
        "                 parallel=False):\n",
        "        \"\"\"da_rnn initialization.\"\"\"\n",
        "        super(DA_rnn, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.parallel = parallel\n",
        "        self.shuffle = False\n",
        "        self.epochs = epochs\n",
        "        self.T = T\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"==> Use accelerator: \", self.device)\n",
        "\n",
        "        self.Encoder = Encoder(input_size=X.shape[1],\n",
        "                               encoder_num_hidden=encoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "        self.Decoder = Decoder(encoder_num_hidden=encoder_num_hidden,\n",
        "                               decoder_num_hidden=decoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.parallel:\n",
        "            self.encoder = nn.DataParallel(self.encoder)\n",
        "            self.decoder = nn.DataParallel(self.decoder)\n",
        "\n",
        "        self.encoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Encoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "        self.decoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Decoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "\n",
        "        # Training set\n",
        "        self.train_timesteps = int(self.X.shape[0] * 0.7)\n",
        "        self.y = self.y - np.mean(self.y[:self.train_timesteps])\n",
        "        self.input_size = self.X.shape[1]\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"training process.\"\"\"\n",
        "        iter_per_epoch = int(np.ceil(self.train_timesteps * 1. / self.batch_size))\n",
        "        self.iter_losses = np.zeros(self.epochs * iter_per_epoch)\n",
        "        self.epoch_losses = np.zeros(self.epochs)\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            if self.shuffle:\n",
        "                ref_idx = np.random.permutation(self.train_timesteps - self.T)\n",
        "            else:\n",
        "                ref_idx = np.array(range(self.train_timesteps - self.T))\n",
        "\n",
        "            idx = 0\n",
        "\n",
        "            while (idx < self.train_timesteps):\n",
        "                # get the indices of X_train\n",
        "                indices = ref_idx[idx:(idx + self.batch_size)]\n",
        "                # x = np.zeros((self.T - 1, len(indices), self.input_size))\n",
        "                x = np.zeros((len(indices), self.T - 1, self.input_size))\n",
        "                y_prev = np.zeros((len(indices), self.T - 1))\n",
        "                y_gt = self.y[indices + self.T]\n",
        "\n",
        "                # format x into 3D tensor\n",
        "                for bs in range(len(indices)):\n",
        "                    x[bs, :, :] = self.X[indices[bs]:(indices[bs] + self.T - 1), :]\n",
        "                    y_prev[bs, :] = self.y[indices[bs]: (indices[bs] + self.T - 1)]\n",
        "\n",
        "                loss = self.train_forward(x, y_prev, y_gt)\n",
        "                self.iter_losses[int(epoch * iter_per_epoch + idx / self.batch_size)] = loss\n",
        "\n",
        "                idx += self.batch_size\n",
        "                n_iter += 1\n",
        "\n",
        "                if n_iter % 10000 == 0 and n_iter != 0:\n",
        "                    for param_group in self.encoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "                    for param_group in self.decoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "\n",
        "                self.epoch_losses[epoch] = np.mean(self.iter_losses[range(\n",
        "                    epoch * iter_per_epoch, (epoch + 1) * iter_per_epoch)])\n",
        "\n",
        "            if epoch % 1 == 0:\n",
        "                print(\"Epochs: \", epoch, \" Iterations: \", n_iter,\n",
        "                      \" Loss: \", self.epoch_losses[epoch])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                y_train_pred = self.test(on_train=True)\n",
        "                y_test_pred = self.test(on_train=False)\n",
        "                y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
        "                plt.ioff()\n",
        "                plt.figure()\n",
        "                plt.plot(range(1, 1 + len(self.y)), self.y, label=\"True\")\n",
        "                plt.plot(range(self.T, len(y_train_pred) + self.T),\n",
        "                         y_train_pred, label='Predicted - Train')\n",
        "                plt.plot(range(self.T + len(y_train_pred), len(self.y) + 1),\n",
        "                         y_test_pred, label='Predicted - Test')\n",
        "                plt.legend(loc='upper left')\n",
        "                plt.show()\n",
        "\n",
        "            # # Save files in last iterations\n",
        "            # if epoch == self.epochs - 1:\n",
        "            #     np.savetxt('../loss.txt', np.array(self.epoch_losses), delimiter=',')\n",
        "            #     np.savetxt('../y_pred.txt',\n",
        "            #                np.array(self.y_pred), delimiter=',')\n",
        "            #     np.savetxt('../y_true.txt',\n",
        "            #                np.array(self.y_true), delimiter=',')\n",
        "\n",
        "    def train_forward(self, X, y_prev, y_gt):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            X:\n",
        "            y_prev:\n",
        "            y_gt: Ground truth label\n",
        "\n",
        "        \"\"\"\n",
        "        # zero gradients\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_weighted, input_encoded = self.Encoder(\n",
        "            Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "        y_pred = self.Decoder(input_encoded, Variable(\n",
        "            torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n",
        "\n",
        "        y_true = Variable(torch.from_numpy(\n",
        "            y_gt).type(torch.FloatTensor).to(self.device))\n",
        "\n",
        "        y_true = y_true.view(-1, 1)\n",
        "        loss = self.criterion(y_pred, y_true)\n",
        "        loss.backward()\n",
        "\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def test(self, on_train=False):\n",
        "        \"\"\"test.\"\"\"\n",
        "\n",
        "        if on_train:\n",
        "            y_pred = np.zeros(self.train_timesteps - self.T + 1)\n",
        "        else:\n",
        "            y_pred = np.zeros(self.X.shape[0] - self.train_timesteps)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(y_pred):\n",
        "            batch_idx = np.array(range(len(y_pred)))[i: (i + self.batch_size)]\n",
        "            X = np.zeros((len(batch_idx), self.T - 1, self.X.shape[1]))\n",
        "            y_history = np.zeros((len(batch_idx), self.T - 1))\n",
        "\n",
        "            for j in range(len(batch_idx)):\n",
        "                if on_train:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1)]\n",
        "                else:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1)]\n",
        "\n",
        "            y_history = Variable(torch.from_numpy(\n",
        "                y_history).type(torch.FloatTensor).to(self.device))\n",
        "            _, input_encoded = self.Encoder(\n",
        "                Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "            y_pred[i:(i + self.batch_size)] = self.Decoder(input_encoded,\n",
        "                                                           y_history).cpu().data.numpy()[:, 0]\n",
        "            i += self.batch_size\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEXkFR3tjUjb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(input_path, debug=True):\n",
        "    \"\"\"Read nasdaq stocks data.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): directory to nasdaq dataset.\n",
        "\n",
        "    Returns:\n",
        "        X (np.ndarray): features.\n",
        "        y (np.ndarray): ground truth.\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path, nrows=250 if debug else None)\n",
        "    # X = df.iloc[:, 0:-1].values\n",
        "    X = df.loc[:, [x for x in df.columns.tolist() if x != 'NDX']].to_numpy() #values() #as_matrix()\n",
        "    # y = df.iloc[:, -1].values\n",
        "    y = np.array(df.NDX)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "JUkG9qJIjmDl",
        "outputId": "afd90284-f11c-4525-9b5f-24a9beb356bb"
      },
      "source": [
        "# Read dataset\n",
        "print(\"==> Load dataset ...\")\n",
        "X, y = read_data(dataroot, debug=False)\n",
        "\n",
        "# Initialize model\n",
        "print(\"==> Initialize DA-RNN model ...\")\n",
        "model = DA_rnn(\n",
        "    X,\n",
        "    y,\n",
        "    ntimestep,\n",
        "    nhidden_encoder,\n",
        "    nhidden_decoder,\n",
        "    batchsize,\n",
        "    lr,\n",
        "    epochs\n",
        ")\n",
        "\n",
        "# Train\n",
        "print(\"==> Start training ...\")\n",
        "model.train()\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.test()\n",
        "\n",
        "fig1 = plt.figure()\n",
        "plt.semilogy(range(len(model.iter_losses)), model.iter_losses)\n",
        "plt.savefig(\"1.png\")\n",
        "plt.close(fig1)\n",
        "\n",
        "fig2 = plt.figure()\n",
        "plt.semilogy(range(len(model.epoch_losses)), model.epoch_losses)\n",
        "plt.savefig(\"2.png\")\n",
        "plt.close(fig2)\n",
        "\n",
        "fig3 = plt.figure()\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig(\"3.png\")\n",
        "plt.close(fig3)\n",
        "print('Finished Training')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Load dataset ...\n",
            "==> Initialize DA-RNN model ...\n",
            "==> Use accelerator:  cuda:0\n",
            "==> Start training ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epochs:  0  Iterations:  222  Loss:  2235.6437259611785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epochs:  1  Iterations:  444  Loss:  1246.5279869343246\n",
            "Epochs:  2  Iterations:  666  Loss:  772.1532730916599\n",
            "Epochs:  3  Iterations:  888  Loss:  517.7824839460957\n",
            "Epochs:  4  Iterations:  1110  Loss:  362.89089577235615\n",
            "Epochs:  5  Iterations:  1332  Loss:  281.1930254899167\n",
            "Epochs:  6  Iterations:  1554  Loss:  214.4827187458674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-23202dced335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==> Start training ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ba6c6c1b5247>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0my_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miter_per_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ba6c6c1b5247>\u001b[0m in \u001b[0;36mtrain_forward\u001b[0;34m(self, X, y_prev, y_gt)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo5VhDcwl0DA",
        "outputId": "5927526e-9456-440b-82c3-64b51d3d1763"
      },
      "source": [
        "!pip install nengolib"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nengolib in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: nengo<3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from nengolib) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from nengolib) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypTmkg5LkbQq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sympy.matrices import Matrix, eye, zeros, ones, diag, GramSchmidt\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from nengolib.signal import Identity, cont2discrete\n",
        "from nengolib.synapses import LegendreDelay\n",
        "from functools import partial\n",
        "\n",
        "def lecun_uniform(tensor):\n",
        "    fan_in = nn.init._calculate_correct_fan(tensor, 'fan_in')\n",
        "    nn.init.uniform_(tensor, -math.sqrt(3 / fan_in), math.sqrt(3 / fan_in))\n",
        "    \n",
        "class LegendreMemoryUnitCell(nn.Module):\n",
        "  def __init__(self, input_dim, units , order, theta,\n",
        "                 input_encoders_initializer=lecun_uniform,\n",
        "                 hidden_encoders_initializer=lecun_uniform,\n",
        "                 memory_encoders_initializer=partial(torch.nn.init.constant_, val=0),\n",
        "                 input_kernel_initializer=torch.nn.init.xavier_normal_,\n",
        "                 hidden_kernel_initializer=torch.nn.init.xavier_normal_,\n",
        "                 memory_kernel_initializer=torch.nn.init.xavier_normal_):\n",
        "    super(LegendreMemoryUnitCell, self).__init__()\n",
        "\n",
        "    self.order = order\n",
        "    self.theta = theta\n",
        "    self.units = units\n",
        "    \n",
        "\n",
        "    realizer = Identity()\n",
        "    self._realizer_result = realizer(LegendreDelay(theta=theta, order=self.order))\n",
        "\n",
        "    self._ss = cont2discrete(self._realizer_result.realization, dt=1., method='zoh')\n",
        "\n",
        "    self._A = self._ss.A - np.eye(order)\n",
        "    self._B = self._ss.B\n",
        "    self._C = self._ss.C\n",
        "\n",
        "    self.AT = nn.Parameter(torch.Tensor(self._A), requires_grad=False)\n",
        "    self.BT = nn.Parameter(torch.Tensor(self._B), requires_grad=False)\n",
        "\n",
        "\n",
        "    self.encoder_input = nn.Parameter(torch.Tensor(1,input_dim), requires_grad=True)\n",
        "    self.encoder_hidden = nn.Parameter(torch.Tensor(1,self.units), requires_grad=True)\n",
        "    self.encoder_memory = nn.Parameter(torch.Tensor(1,self.order ), requires_grad=True)\n",
        "    self.kernel_input = nn.Parameter(torch.Tensor(self.units, input_dim), requires_grad=True)\n",
        "    self.kernel_hidden = nn.Parameter(torch.Tensor(self.units, self.units), requires_grad=True)\n",
        "    self.kernel_memory = nn.Parameter(torch.Tensor(self.units, self.order), requires_grad=True)\n",
        "    \n",
        "\n",
        "    input_encoders_initializer(self.encoder_input)\n",
        "    hidden_encoders_initializer(self.encoder_hidden)\n",
        "    memory_encoders_initializer(self.encoder_memory)\n",
        "    input_kernel_initializer(self.kernel_input)\n",
        "    hidden_kernel_initializer(self.kernel_hidden)\n",
        "    memory_kernel_initializer(self.kernel_memory)\n",
        "\n",
        "  def EulerOdeSolver(self):\n",
        "    A_hat = (self.step_delta_t/self.theta)*self.AT + torch.eye(self.order,self.d_order_ode)\n",
        "    B_hat = (self.step_delta_t/self.theta)*self.BT\n",
        "\n",
        "    return A_hat, B_hat\n",
        "\n",
        "  def forward(self, xt, states):\n",
        "    ht, mt = states\n",
        "    \n",
        "    ut = F.linear(xt, self.encoder_input) + F.linear(ht, self.encoder_hidden) + F.linear(mt, self.encoder_memory)\n",
        "    \n",
        "    mt = mt + F.linear(mt, self.AT) + F.linear(ut, self.BT)\n",
        "    \n",
        "    ht = nn.Tanh()(F.linear(xt, self.kernel_input) + F.linear(ht, self.kernel_hidden) + F.linear(mt, self.kernel_memory))\n",
        "\n",
        "    return ht, (ht, mt)\n",
        "\n",
        "class LegendreMemoryUnit(nn.Module):\n",
        "  def __init__(self, input_dim, units , order, theta):\n",
        "    super(LegendreMemoryUnit, self).__init__()\n",
        "\n",
        "    self.units = units\n",
        "    self.order = order\n",
        "\n",
        "    self.lmucell = LegendreMemoryUnitCell(input_dim, units , order, theta)\n",
        "\n",
        "  def forward(self, xt, hx=None):\n",
        "    outputs = []\n",
        "    \n",
        "    if hx is None:\n",
        "      h0 = torch.zeros(xt.size(0),self.units).cuda()\n",
        "      m0 = torch.zeros(xt.size(0),self.order).cuda()\n",
        "    else:\n",
        "      h0, m0 = hx\n",
        "    # print(h0.shape, m0.shape, xt.size(), self.units, xt.size(0), self.order)\n",
        "    states = (h0,m0)\n",
        "    for i in range(xt.size(1)):\n",
        "      out, states = self.lmucell(xt[:,i,:], states)\n",
        "      outputs += [out]\n",
        "    return torch.stack(outputs).permute(1,0,2), states\n",
        "    # return torch.stack(outputs).permute(1,0,2), states"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odxNMFwxjp6n"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "lmu_order = 128\n",
        "lmu_theta = 4\n",
        "\n",
        "class Encoder_lmu(nn.Module):\n",
        "    \"\"\"encoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T,\n",
        "                 input_size,\n",
        "                 encoder_num_hidden,\n",
        "                 parallel=False):\n",
        "        \"\"\"Initialize an encoder in DA_RNN.\"\"\"\n",
        "        super(Encoder_lmu, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.input_size = input_size\n",
        "        self.parallel = parallel\n",
        "        self.T = T\n",
        "\n",
        "        # Fig 1. Temporal Attention Mechanism: Encoder is LSTM\n",
        "        self.encoder_lstm = LegendreMemoryUnit(self.input_size, self.encoder_num_hidden, lmu_order, lmu_theta) #nn.LSTM(\n",
        "        #     input_size=self.input_size,\n",
        "        #     hidden_size=self.encoder_num_hidden,\n",
        "        #     num_layers = 1\n",
        "        # )\n",
        "\n",
        "        # Construct Input Attention Mechanism via deterministic attention model\n",
        "        # Eq. 8: W_e[h_{t-1}; s_{t-1}] + U_e * x^k\n",
        "        self.encoder_attn = nn.Linear(\n",
        "            in_features=lmu_order + self.encoder_num_hidden + self.T - 1,\n",
        "            out_features=1\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"forward.\n",
        "\n",
        "        Args:\n",
        "            X: input data\n",
        "\n",
        "        \"\"\"\n",
        "        X_tilde = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.input_size).zero_())\n",
        "        X_encoded = Variable(X.data.new(\n",
        "            X.size(0), self.T - 1, self.encoder_num_hidden).zero_())\n",
        "\n",
        "        # Eq. 8, parameters not in nn.Linear but to be learnt\n",
        "        # v_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.input_size, self.T).uniform_(0, 1), requires_grad=True)\n",
        "        # U_e = torch.nn.Parameter(data=torch.empty(\n",
        "        #     self.T, self.T).uniform_(0, 1), requires_grad=True)\n",
        "\n",
        "        # h_n, s_n: initial states with dimention hidden_size\n",
        "        h_n = self._init_states(X, self.encoder_num_hidden)\n",
        "        s_n = self._init_states(X, lmu_order)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            # batch_size * input_size * (2 * hidden_size + T - 1)\n",
        "            x = torch.cat((h_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           s_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
        "                           X.permute(0, 2, 1)), dim=2)\n",
        "\n",
        "            x = self.encoder_attn(\n",
        "                x.view(-1, self.encoder_num_hidden + lmu_order + self.T - 1))\n",
        "\n",
        "            # get weights by softmax\n",
        "            alpha = F.softmax(x.view(-1, self.input_size))\n",
        "\n",
        "            # get new input for LSTM\n",
        "            x_tilde = torch.mul(alpha, X[:, t, :])\n",
        "\n",
        "            # Fix the warning about non-contiguous memory\n",
        "            # https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
        "            # self.encoder_lstm.flatten_parameters() #Yash Gupta commented this as it is mostly optional\n",
        "\n",
        "            # encoder LSTM\n",
        "            _, final_state = self.encoder_lstm(x_tilde.unsqueeze(0), (h_n[0, :, :], s_n[0, :, :]))\n",
        "            h_n = final_state[0].unsqueeze(0)\n",
        "            s_n = final_state[1].unsqueeze(0)\n",
        "\n",
        "            X_tilde[:, t, :] = x_tilde\n",
        "            X_encoded[:, t, :] = h_n\n",
        "\n",
        "        return X_tilde, X_encoded\n",
        "\n",
        "    def _init_states(self, X, sz):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "        \"\"\"\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), sz).zero_())\n",
        "\n",
        "\n",
        "class Decoder_lmu(nn.Module):\n",
        "    \"\"\"decoder in DA_RNN.\"\"\"\n",
        "\n",
        "    def __init__(self, T, decoder_num_hidden, encoder_num_hidden):\n",
        "        \"\"\"Initialize a decoder in DA_RNN.\"\"\"\n",
        "        super(Decoder_lmu, self).__init__()\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.T = T\n",
        "\n",
        "        self.attn_layer = nn.Sequential(\n",
        "            nn.Linear(lmu_order + decoder_num_hidden + encoder_num_hidden, encoder_num_hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(encoder_num_hidden, 1)\n",
        "        )\n",
        "        self.lstm_layer = LegendreMemoryUnit(1, decoder_num_hidden, lmu_order, lmu_theta) #nn.LSTM(\n",
        "        #     input_size=1,\n",
        "        #     hidden_size=decoder_num_hidden\n",
        "        # )\n",
        "        self.fc = nn.Linear(encoder_num_hidden + 1, 1)\n",
        "        self.fc_final = nn.Linear(decoder_num_hidden + encoder_num_hidden, 1)\n",
        "\n",
        "        self.fc.weight.data.normal_()\n",
        "\n",
        "    def forward(self, X_encoded, y_prev):\n",
        "        \"\"\"forward.\"\"\"\n",
        "        d_n = self._init_states(X_encoded, self.decoder_num_hidden)\n",
        "        c_n = self._init_states(X_encoded, lmu_order)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "\n",
        "            x = torch.cat((d_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           c_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
        "                           X_encoded), dim=2)\n",
        "\n",
        "            beta = F.softmax(self.attn_layer(\n",
        "                x.view(-1, lmu_order + self.decoder_num_hidden + self.encoder_num_hidden)).view(-1, self.T - 1))\n",
        "\n",
        "            # Eqn. 14: compute context vector\n",
        "            # batch_size * encoder_hidden_size\n",
        "            context = torch.bmm(beta.unsqueeze(1), X_encoded)[:, 0, :]\n",
        "            if t < self.T - 1:\n",
        "                # Eqn. 15\n",
        "                # batch_size * 1\n",
        "                y_tilde = self.fc(\n",
        "                    torch.cat((context, y_prev[:, t].unsqueeze(1)), dim=1))\n",
        "\n",
        "                # Eqn. 16: LSTM\n",
        "                # self.lstm_layer.flatten_parameters()\n",
        "                _, final_states = self.lstm_layer(\n",
        "                    y_tilde.unsqueeze(0), (d_n[0, :, :], c_n[0, :, :]))\n",
        "\n",
        "                d_n = final_states[0].unsqueeze(0)  # 1 * batch_size * decoder_num_hidden\n",
        "                c_n = final_states[1].unsqueeze(0)  # 1 * batch_size * decoder_num_hidden\n",
        "\n",
        "        # Eqn. 22: final output\n",
        "        y_pred = self.fc_final(torch.cat((d_n[0], context), dim=1))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def _init_states(self, X, sz):\n",
        "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
        "\n",
        "        Args:\n",
        "            X\n",
        "        Returns:\n",
        "            initial_hidden_states\n",
        "\n",
        "        \"\"\"\n",
        "        # hidden state and cell state [num_layers*num_directions, batch_size, hidden_size]\n",
        "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
        "        return Variable(X.data.new(1, X.size(0), sz).zero_())\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "class DA_rnn_lmu(nn.Module):\n",
        "    \"\"\"da_rnn.\"\"\"\n",
        "\n",
        "    def __init__(self, X, y, T,\n",
        "                 encoder_num_hidden,\n",
        "                 decoder_num_hidden,\n",
        "                 batch_size,\n",
        "                 learning_rate,\n",
        "                 epochs,\n",
        "                 parallel=False):\n",
        "        \"\"\"da_rnn initialization.\"\"\"\n",
        "        super(DA_rnn_lmu, self).__init__()\n",
        "        self.encoder_num_hidden = encoder_num_hidden\n",
        "        self.decoder_num_hidden = decoder_num_hidden\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.parallel = parallel\n",
        "        self.shuffle = False\n",
        "        self.epochs = epochs\n",
        "        self.T = T\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(\"==> Use accelerator: \", self.device)\n",
        "\n",
        "        self.Encoder = Encoder_lmu(input_size=X.shape[1],\n",
        "                               encoder_num_hidden=encoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "        self.Decoder = Decoder_lmu(encoder_num_hidden=encoder_num_hidden,\n",
        "                               decoder_num_hidden=decoder_num_hidden,\n",
        "                               T=T).to(self.device)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "        if self.parallel:\n",
        "            self.encoder = nn.DataParallel(self.encoder)\n",
        "            self.decoder = nn.DataParallel(self.decoder)\n",
        "\n",
        "        self.encoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Encoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "        self.decoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
        "                                                          self.Decoder.parameters()),\n",
        "                                            lr=self.learning_rate)\n",
        "\n",
        "        # Training set\n",
        "        self.train_timesteps = int(self.X.shape[0] * 0.7)\n",
        "        self.y = self.y - np.mean(self.y[:self.train_timesteps])\n",
        "        self.input_size = self.X.shape[1]\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"training process.\"\"\"\n",
        "        iter_per_epoch = int(np.ceil(self.train_timesteps * 1. / self.batch_size))\n",
        "        self.iter_losses = np.zeros(self.epochs * iter_per_epoch)\n",
        "        self.epoch_losses = np.zeros(self.epochs)\n",
        "\n",
        "        n_iter = 0\n",
        "\n",
        "        for epoch in tqdm(range(self.epochs)):\n",
        "            if self.shuffle:\n",
        "                ref_idx = np.random.permutation(self.train_timesteps - self.T)\n",
        "            else:\n",
        "                ref_idx = np.array(range(self.train_timesteps - self.T))\n",
        "\n",
        "            idx = 0\n",
        "\n",
        "            for j in tqdm(range(0, self.train_timesteps, self.batch_size)): #while (idx < self.train_timesteps):\n",
        "                # get the indices of X_train\n",
        "                indices = ref_idx[idx:(idx + self.batch_size)]\n",
        "                # x = np.zeros((self.T - 1, len(indices), self.input_size))\n",
        "                x = np.zeros((len(indices), self.T - 1, self.input_size))\n",
        "                y_prev = np.zeros((len(indices), self.T - 1))\n",
        "                y_gt = self.y[indices + self.T]\n",
        "\n",
        "                # format x into 3D tensor\n",
        "                for bs in range(len(indices)):\n",
        "                    x[bs, :, :] = self.X[indices[bs]:(indices[bs] + self.T - 1), :]\n",
        "                    y_prev[bs, :] = self.y[indices[bs]: (indices[bs] + self.T - 1)]\n",
        "\n",
        "                loss = self.train_forward(x, y_prev, y_gt)\n",
        "                self.iter_losses[int(epoch * iter_per_epoch + idx / self.batch_size)] = loss\n",
        "\n",
        "                idx += self.batch_size\n",
        "                n_iter += 1\n",
        "\n",
        "                if n_iter % 10000 == 0 and n_iter != 0:\n",
        "                    for param_group in self.encoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "                    for param_group in self.decoder_optimizer.param_groups:\n",
        "                        param_group['lr'] = param_group['lr'] * 0.9\n",
        "\n",
        "                self.epoch_losses[epoch] = np.mean(self.iter_losses[range(\n",
        "                    epoch * iter_per_epoch, (epoch + 1) * iter_per_epoch)])\n",
        "\n",
        "            if epoch % 1 == 0:\n",
        "                print(\"Epochs: \", epoch, \" Iterations: \", n_iter,\n",
        "                      \" Loss: \", self.epoch_losses[epoch])\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                y_train_pred = self.test(on_train=True)\n",
        "                y_test_pred = self.test(on_train=False)\n",
        "                y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
        "                plt.ioff()\n",
        "                plt.figure()\n",
        "                plt.plot(range(1, 1 + len(self.y)), self.y, label=\"True\")\n",
        "                plt.plot(range(self.T, len(y_train_pred) + self.T),\n",
        "                         y_train_pred, label='Predicted - Train')\n",
        "                plt.plot(range(self.T + len(y_train_pred), len(self.y) + 1),\n",
        "                         y_test_pred, label='Predicted - Test')\n",
        "                plt.legend(loc='upper left')\n",
        "                plt.show()\n",
        "\n",
        "            # # Save files in last iterations\n",
        "            # if epoch == self.epochs - 1:\n",
        "            #     np.savetxt('../loss.txt', np.array(self.epoch_losses), delimiter=',')\n",
        "            #     np.savetxt('../y_pred.txt',\n",
        "            #                np.array(self.y_pred), delimiter=',')\n",
        "            #     np.savetxt('../y_true.txt',\n",
        "            #                np.array(self.y_true), delimiter=',')\n",
        "\n",
        "    def train_forward(self, X, y_prev, y_gt):\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            X:\n",
        "            y_prev:\n",
        "            y_gt: Ground truth label\n",
        "\n",
        "        \"\"\"\n",
        "        # zero gradients\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        input_weighted, input_encoded = self.Encoder(\n",
        "            Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "        y_pred = self.Decoder(input_encoded, Variable(\n",
        "            torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n",
        "\n",
        "        y_true = Variable(torch.from_numpy(\n",
        "            y_gt).type(torch.FloatTensor).to(self.device))\n",
        "\n",
        "        y_true = y_true.view(-1, 1)\n",
        "        loss = self.criterion(y_pred, y_true)\n",
        "        loss.backward()\n",
        "\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def test(self, on_train=False):\n",
        "        \"\"\"test.\"\"\"\n",
        "\n",
        "        if on_train:\n",
        "            y_pred = np.zeros(self.train_timesteps - self.T + 1)\n",
        "        else:\n",
        "            y_pred = np.zeros(self.X.shape[0] - self.train_timesteps)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(y_pred):\n",
        "            batch_idx = np.array(range(len(y_pred)))[i: (i + self.batch_size)]\n",
        "            X = np.zeros((len(batch_idx), self.T - 1, self.X.shape[1]))\n",
        "            y_history = np.zeros((len(batch_idx), self.T - 1))\n",
        "\n",
        "            for j in range(len(batch_idx)):\n",
        "                if on_train:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j], batch_idx[j] + self.T - 1)]\n",
        "                else:\n",
        "                    X[j, :, :] = self.X[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1), :]\n",
        "                    y_history[j, :] = self.y[range(\n",
        "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1)]\n",
        "\n",
        "            y_history = Variable(torch.from_numpy(\n",
        "                y_history).type(torch.FloatTensor).to(self.device))\n",
        "            _, input_encoded = self.Encoder(\n",
        "                Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
        "            y_pred[i:(i + self.batch_size)] = self.Decoder(input_encoded,\n",
        "                                                           y_history).cpu().data.numpy()[:, 0]\n",
        "            i += self.batch_size\n",
        "\n",
        "        return y_pred"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg94r_OxW5F"
      },
      "source": [
        "batchsize = 128\n",
        "nhidden_encoder = 128\n",
        "nhidden_decoder = 128\n",
        "ntimestep = 10\n",
        "lr = 0.001\n",
        "epochs = 50\n",
        "lmu_order = 4"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "661fbcd29c314cbb84d623b3f1b5de80",
            "dee2cb41b7404742aea674c8d0a81298",
            "676d93d9305c470785b252500341f51d",
            "a1dba9600f864f3795a479da6d761ec2",
            "ce15f63ec8d94ddab7d643daa25f5759",
            "623633d8cab140ea81be7ddb15545249",
            "a43b29b7369a42b298de59cee27c37a2",
            "2ccc19839b1a4552b439382802f76a4e",
            "60ececb80395486f80146f7fab5e57b6",
            "7c5ee229a7f8487597aa114bfb534855",
            "cc1eaecb482343d098ab7e959674d7ca",
            "9e0947b4c4ec4df99a224517f5e1c753",
            "c3e001f9d52e43dd88aeb32fc3a303a7",
            "6249147f9efe468686eb8001249f5ce4",
            "bf1b3dacd54d42448a65a36f33894401",
            "6223ef43380540f89f420fe7daedad49"
          ]
        },
        "id": "iNdnPkeel5Hy",
        "outputId": "19e9f63f-482d-4120-8483-33723da409be"
      },
      "source": [
        "# Read dataset\n",
        "print(\"==> Load dataset ...\")\n",
        "X, y = read_data(dataroot, debug=False)\n",
        "\n",
        "# Initialize model\n",
        "print(\"==> Initialize DA-RNN model ...\")\n",
        "model = DA_rnn_lmu(\n",
        "    X,\n",
        "    y,\n",
        "    ntimestep,\n",
        "    nhidden_encoder,\n",
        "    nhidden_decoder,\n",
        "    batchsize,\n",
        "    lr,\n",
        "    epochs\n",
        ")\n",
        "\n",
        "# Train\n",
        "print(\"==> Start training ...\")\n",
        "model.train()\n",
        "\n",
        "# Prediction\n",
        "y_pred = model.test()\n",
        "\n",
        "fig1 = plt.figure()\n",
        "plt.semilogy(range(len(model.iter_losses)), model.iter_losses)\n",
        "plt.savefig(\"1.png\")\n",
        "plt.close(fig1)\n",
        "\n",
        "fig2 = plt.figure()\n",
        "plt.semilogy(range(len(model.epoch_losses)), model.epoch_losses)\n",
        "plt.savefig(\"2.png\")\n",
        "plt.close(fig2)\n",
        "\n",
        "fig3 = plt.figure()\n",
        "plt.plot(y_pred, label='Predicted')\n",
        "plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig(\"3.png\")\n",
        "plt.close(fig3)\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Load dataset ...\n",
            "==> Initialize DA-RNN model ...\n",
            "==> Use accelerator:  cuda:0\n",
            "==> Start training ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "661fbcd29c314cbb84d623b3f1b5de80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60ececb80395486f80146f7fab5e57b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=222.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:142: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8YrbpV6mBHU"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}