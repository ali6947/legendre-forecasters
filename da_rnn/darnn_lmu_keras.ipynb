{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "darnn_lmu_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashgupta-7/legendre-forecasters/blob/main/da_rnn/darnn_lmu_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIOv-ZSbIkrC"
      },
      "source": [
        "#!git clone https://github.com/kaelzhang/DA-RNN-in-Tensorflow-2-and-PyTorch/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9y3V66hVPx_",
        "outputId": "afa690eb-2dae-479f-9265-82ec305c5881"
      },
      "source": [
        "# !git clone https://github.com/nengo/keras-lmu"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'keras-lmu' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeA84aWPGWCI"
      },
      "source": [
        "# import keras_lmu"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4udNOJrIs0b",
        "outputId": "03953931-36d0-4f58-cd21-2e7c96565d0a"
      },
      "source": [
        "cd /content/DA-RNN-in-Tensorflow-2-and-PyTorch/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DA-RNN-in-Tensorflow-2-and-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t-RZDPEQRZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20faeb5-15dc-487e-90ff-5ec23131f6d2"
      },
      "source": [
        "# !pip install keras_lmu\n",
        "# !pip install get_rolling_window\n",
        "!ls /content/keras-lmu/keras_lmu/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__.py  layers.py\ttests  version.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo29trKWG4b2"
      },
      "source": [
        "from typing import Optional\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import (\n",
        "    Layer,\n",
        "    LSTM,\n",
        "    Dense,\n",
        "    Permute\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from da_rnn.common import (\n",
        "    check_T\n",
        ")\n",
        "\n",
        "import os\n",
        "os.sys.path.insert(0, \"/content/keras-lmu/\")\n",
        "# from sibling import module\n",
        "import keras_lmu\n",
        "tf.random.set_seed(\n",
        "    42\n",
        ")"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHyXmmZ3Ig5k"
      },
      "source": [
        "class InputAttention(Layer):\n",
        "    T: int\n",
        "\n",
        "    def __init__(self, T, **kwargs):\n",
        "        \"\"\"\n",
        "        Calculates the encoder attention weight Alpha_t at time t\n",
        "        Args:\n",
        "            T (int): the size (time steps) of the window\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(name='input_attention', **kwargs)\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.W_e = Dense(T)\n",
        "        self.U_e = Dense(T)\n",
        "        self.v_e = Dense(1)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_state,\n",
        "        cell_state,\n",
        "        X\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_state: hidden state of shape (batch_size, m) at time t - 1; (batch_size, m) if LMU\n",
        "            cell_state: cell state of shape (batch_size, m) at time t - 1; (batch_size, d) if LMU\n",
        "            X: the n driving (exogenous) series of shape (batch_size, T, n)\n",
        "        Returns:\n",
        "            The attention weights (Alpha_t) at time t, i.e.\n",
        "            (a_t__1, a_t__2, ..., a_t__n)\n",
        "        \"\"\"\n",
        "\n",
        "        n = X.shape[2]\n",
        "\n",
        "        # [h_t-1; s_t-1]\n",
        "        hs = K.repeat(\n",
        "            tf.concat([hidden_state, cell_state], axis=-1),\n",
        "            # -> (batch_size, m * 2); (batch_size, m+d) if LMU\n",
        "            n\n",
        "        )\n",
        "        # -> (batch_size, n, m * 2); (batch_size, n, m + d) if LMU\n",
        "\n",
        "        tanh = tf.math.tanh(\n",
        "            tf.concat([\n",
        "                self.W_e(hs),\n",
        "                # -> (batch_size, n, T)\n",
        "\n",
        "                self.U_e(\n",
        "                    Permute((2, 1))(X)\n",
        "                    # -> (batch_size, n, T)\n",
        "                ),\n",
        "                # -> (batch_size, n, T)\n",
        "            ], axis=-1)\n",
        "            # -> (batch_size, n, T * 2)\n",
        "        )\n",
        "        # -> (batch_size, n, T * 2)\n",
        "\n",
        "        # Equation 8:\n",
        "        e = self.v_e(tanh)\n",
        "        # -> (batch_size, n, 1)\n",
        "\n",
        "        # Equation: 9\n",
        "        return tf.nn.softmax(\n",
        "            Permute((2, 1))(e)\n",
        "            # -> (batch_size, 1, n)\n",
        "        )\n",
        "        # -> (batch_size, 1, n)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjnm5mTU3zsS"
      },
      "source": [
        "# !pip uninstall keras_lmu"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCd2Dl_g4kIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05b3391-666c-468c-a857-09deda73e3f7"
      },
      "source": [
        "import keras_lmu\n",
        "# import gputil\n",
        "import tensorflow as tf \n",
        "if tf.test.gpu_device_name(): \n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "   print(\"Please install GPU version of TF\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZnAdSmCI-lB"
      },
      "source": [
        "class Encoder(Layer):\n",
        "    T: int\n",
        "    m: int\n",
        "    d: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        d: int,\n",
        "        lmu=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Generates the new input X_tilde for encoder\n",
        "        Args:\n",
        "            T (int): the size (time steps) of the window\n",
        "            m (int): the number of the encoder hidden states\n",
        "            d (int): the number of the encoder cell states; m=d if LSTM\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(name='encoder_input', **kwargs)\n",
        "\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.lmu = lmu\n",
        "        if not lmu:\n",
        "            assert(m==d)\n",
        "\n",
        "        if self.lmu:\n",
        "          self.input_lstm = keras_lmu.LMUCell(memory_d=self.d, order=self.d, theta=self.T, #LMU\n",
        "                hidden_cell = tf.keras.layers.SimpleRNNCell(m), # m -> \tPositive integer, dimensionality of the output space.\n",
        "                hidden_to_memory=False,\n",
        "                memory_to_memory=False,\n",
        "                input_to_hidden=True,\n",
        "                kernel_initializer=\"ones\",\n",
        "               #return_sequences = False\n",
        "            )\n",
        "        else:\n",
        "          self.input_lstm = LSTM(m, return_state=True)\n",
        "        self.input_attention = InputAttention(T)\n",
        "\n",
        "    def call(self, X) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            X: the n driving (exogenous) series of shape (batch_size, T, n)\n",
        "        Returns:\n",
        "            The encoder hidden state of shape (batch_size, T, m)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = K.shape(X)[0]\n",
        "\n",
        "        hidden_state = tf.zeros((batch_size, self.m))\n",
        "        if self.lmu:\n",
        "          cell_state = tf.zeros((batch_size, self.d*self.d))\n",
        "        else:\n",
        "          cell_state = tf.zeros((batch_size, self.m))\n",
        "\n",
        "        X_encoded = []\n",
        "\n",
        "        for t in range(self.T):\n",
        "            Alpha_t = self.input_attention(hidden_state, cell_state, X)\n",
        "\n",
        "            # Equation 10\n",
        "            X_tilde_t = tf.multiply(\n",
        "                Alpha_t,\n",
        "                # TODO:\n",
        "                # make sure it can share the underlying data\n",
        "                X[:, None, t, :]\n",
        "            )\n",
        "            # -> (batch_size, 1, n)\n",
        "\n",
        "            # Equation 11\n",
        "            # print(\"Xtilde\", X_tilde_t.shape, \"Hidden\", hidden_state.shape, \"Mem\", cell_state.shape)\n",
        "            \n",
        "            if self.lmu:\n",
        "              X_tilde_t = X_tilde_t[:, 0, :]\n",
        "              # print(\"Xtilde\", X_tilde_t.shape)\n",
        "              # print(\"Out\", self.input_lstm(X_tilde_t,states = [hidden_state, cell_state])[0].shape)\n",
        "              _ , final_state = self.input_lstm(X_tilde_t,\n",
        "              states = [hidden_state, cell_state])\n",
        "              \n",
        "              hidden_state = final_state[0]\n",
        "              cell_state = final_state[-1]\n",
        "            else:\n",
        "              hidden_state, _, cell_state = self.input_lstm(\n",
        "                X_tilde_t,\n",
        "                initial_state=[hidden_state, cell_state]\n",
        "            )\n",
        "\n",
        "            X_encoded.append(\n",
        "                hidden_state[:, None, :]\n",
        "                # -> (batch_size, 1, m)\n",
        "            )\n",
        "\n",
        "        return tf.concat(X_encoded, axis=1)\n",
        "        # -> (batch_size, T, m)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'd': self.d\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "301L6e2BJBK8"
      },
      "source": [
        "class TemporalAttention(Layer):\n",
        "    m: int\n",
        "\n",
        "    def __init__(self, m: int, **kwargs):\n",
        "        \"\"\"\n",
        "        Calculates the attention weights::\n",
        "            Beta_t = (beta_t__1, ..., beta_t__i, ..., beta_t__T) (1 <= i <= T)\n",
        "        for each encoder hidden state h_t at the time step t\n",
        "        Args:\n",
        "            m (int): the number of the encoder hidden states\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(name='temporal_attention', **kwargs)\n",
        "\n",
        "        self.m = m\n",
        "\n",
        "        self.W_d = Dense(m)\n",
        "        self.U_d = Dense(m)\n",
        "        self.v_d = Dense(1)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        hidden_state,\n",
        "        cell_state,\n",
        "        X_encoded\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_state: hidden state `d` of shape (batch_size, p)\n",
        "            cell_state: cell state `s` of shape (batch_size, p)\n",
        "            X_encoded: the encoder hidden states (batch_size, T, m)\n",
        "        Returns:\n",
        "            The attention weights for encoder hidden states (beta_t)\n",
        "        \"\"\"\n",
        "\n",
        "        # Equation 12\n",
        "        l = self.v_d(\n",
        "            tf.math.tanh(\n",
        "                tf.concat([\n",
        "                    self.W_d(\n",
        "                        K.repeat(\n",
        "                            tf.concat([hidden_state, cell_state], axis=-1),\n",
        "                            # -> (batch_size, p * 2)\n",
        "                            X_encoded.shape[1]\n",
        "                        )\n",
        "                        # -> (batch_size, T, p * 2)\n",
        "                    ),\n",
        "                    # -> (batch_size, T, m)\n",
        "                    self.U_d(X_encoded)\n",
        "                ], axis=-1)\n",
        "                # -> (batch_size, T, m * 2)\n",
        "            )\n",
        "            # -> (batch_size, T, m)\n",
        "        )\n",
        "        # -> (batch_size, T, 1)\n",
        "\n",
        "        # Equation 13\n",
        "        return tf.nn.softmax(l, axis=1)\n",
        "        # -> (batch_size, T, 1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'm': self.m\n",
        "        })\n",
        "        return config\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UdhSoJpJD3_"
      },
      "source": [
        "class Decoder(Layer):\n",
        "    T: int\n",
        "    m: int\n",
        "    p: int\n",
        "    d: int\n",
        "    y_dim: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        p: int,\n",
        "        d: int,\n",
        "        y_dim: int,\n",
        "        lmu=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Calculates y_hat_T\n",
        "        Args:\n",
        "            T (int): the size (time steps) of the window\n",
        "            m (int): the number of the encoder hidden states\n",
        "            p (int): the number of the decoder hidden states\n",
        "            y_dim (int): prediction dimentionality\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(name='decoder', **kwargs)\n",
        "\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.p = p\n",
        "        self.d = d\n",
        "        self.lmu = lmu\n",
        "        self.y_dim = y_dim\n",
        "\n",
        "        self.temp_attention = TemporalAttention(m)\n",
        "        self.dense = Dense(1)\n",
        "        if not lmu:\n",
        "            assert(p==d)\n",
        "        \n",
        "        if self.lmu:\n",
        "          self.decoder_lstm = keras_lmu.LMUCell(memory_d=self.d, order=self.d, theta=self.T, #LMU\n",
        "                hidden_cell = tf.keras.layers.SimpleRNNCell(p), # m -> \tPositive integer, dimensionality of the output space.\n",
        "                hidden_to_memory=False,\n",
        "                memory_to_memory=False,\n",
        "                input_to_hidden=True,\n",
        "                kernel_initializer=\"ones\",\n",
        "               #return_sequences = False\n",
        "            )\n",
        "        else:\n",
        "          self.decoder_lstm = LSTM(p, return_state=True)\n",
        "\n",
        "        self.Wb = Dense(p)\n",
        "        self.vb = Dense(y_dim)\n",
        "\n",
        "    def call(self, Y, X_encoded) -> tf.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Y: prediction data of shape (batch_size, T - 1, y_dim) from time 1 to time T - 1. See Figure 1(b) in the paper\n",
        "            X_encoded: encoder hidden states of shape (batch_size, T, m)\n",
        "        Returns:\n",
        "            y_hat_T: the prediction of shape (batch_size, y_dim)\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = K.shape(X_encoded)[0]\n",
        "        hidden_state = tf.zeros((batch_size, self.p))\n",
        "        if self.lmu:\n",
        "          cell_state = tf.zeros((batch_size, self.d*self.d))\n",
        "        else:\n",
        "          cell_state = tf.zeros((batch_size, self.p))\n",
        "\n",
        "        # c in the paper\n",
        "        context_vector = tf.zeros((batch_size, 1, self.m))\n",
        "        # -> (batch_size, 1, m)\n",
        "\n",
        "        for t in range(self.T - 1):\n",
        "            Beta_t = self.temp_attention(\n",
        "                hidden_state,\n",
        "                cell_state,\n",
        "                X_encoded\n",
        "            )\n",
        "            # -> (batch_size, T, 1)\n",
        "\n",
        "            # Equation 14\n",
        "            context_vector = tf.matmul(\n",
        "                Beta_t, X_encoded, transpose_a=True\n",
        "            )\n",
        "            # -> (batch_size, 1, m)\n",
        "\n",
        "            # Equation 15\n",
        "            y_tilde = self.dense(\n",
        "                tf.concat([Y[:, None, t, :], context_vector], axis=-1)\n",
        "                # -> (batch_size, 1, y_dim + m)\n",
        "            )\n",
        "            # -> (batch_size, 1, 1)\n",
        "\n",
        "            # Equation 16\n",
        "            if self.lmu:\n",
        "              y_tilde = y_tilde[:, 0, :]\n",
        "              _ , final_state = self.decoder_lstm(y_tilde,\n",
        "              states = [hidden_state, cell_state])\n",
        "              \n",
        "              hidden_state = final_state[0]\n",
        "              cell_state = final_state[-1]\n",
        "            else:\n",
        "              hidden_state, _, cell_state = self.decoder_lstm(\n",
        "                  y_tilde,\n",
        "                  initial_state=[hidden_state, cell_state]\n",
        "              )\n",
        "            # -> (batch_size, p)\n",
        "\n",
        "        concatenated = tf.concat(\n",
        "            [hidden_state[:, None, :], context_vector], axis=-1\n",
        "        )\n",
        "        # -> (batch_size, 1, m + p)\n",
        "\n",
        "        # Equation 22\n",
        "        y_hat_T = self.vb(\n",
        "            self.Wb(concatenated)\n",
        "            # -> (batch_size, 1, p)\n",
        "        )\n",
        "        # -> (batch_size, 1, y_dim)\n",
        "\n",
        "        return tf.squeeze(y_hat_T, axis=1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'p': self.p,\n",
        "            'y_dim': self.y_dim\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9FVwxhHJH8R"
      },
      "source": [
        "class DARNN(Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        T: int,\n",
        "        m: int,\n",
        "        d: int,\n",
        "        p: Optional[int] = None,\n",
        "        y_dim: int = 1,\n",
        "        lmu=False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            T (int): the size (time steps) of the window\n",
        "            m (int): the number of the encoder hidden states\n",
        "            p (:obj:`int`, optional): the number of the decoder hidden states. Defaults to `m`\n",
        "            y_dim (:obj:`int`, optional): prediction dimentionality. Defaults to `1`\n",
        "        Model Args:\n",
        "            inputs: the concatenation of\n",
        "            - n driving series (x_1, x_2, ..., x_T) and\n",
        "            - the previous (historical) T - 1 predictions (y_1, y_2, ..., y_Tminus1, zero)\n",
        "        `inputs` Explanation::\n",
        "            inputs_t = (x_t__1, x_t__2, ..., x_t__n, y_t__1, y_t__2, ..., y_t__d)\n",
        "            where\n",
        "            - d is the prediction dimention\n",
        "            - y_T__i = 0, 1 <= i <= d.\n",
        "            Actually, the model will not use the value of y_T\n",
        "        Usage::\n",
        "            model = DARNN(10, 64, 64)\n",
        "            y_hat = model(inputs)\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(name='DARNN')\n",
        "\n",
        "        check_T(T)\n",
        "\n",
        "        self.T = T\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.p = p or m\n",
        "        self.y_dim = y_dim\n",
        "        self.lmu = lmu\n",
        "\n",
        "        self.encoder = Encoder(T, m, d=self.d, lmu=self.lmu)\n",
        "        self.decoder = Decoder(T, m, p, d=self.d, lmu=self.lmu, y_dim=y_dim)\n",
        "\n",
        "    # Equation 1\n",
        "    def call(self, inputs):\n",
        "        X = inputs[:, :, :-self.y_dim]\n",
        "        # -> (batch_size, T, n)\n",
        "\n",
        "        # Y's window size is one less than X's\n",
        "        # so, abandon `y_T`\n",
        "\n",
        "        # By doing this, there are some benefits which makes it pretty easy to\n",
        "        # process datasets\n",
        "        Y = inputs[:, :, -self.y_dim:]\n",
        "        # -> (batch_size, T - 1, y_dim)\n",
        "\n",
        "        X_encoded = self.encoder(X)\n",
        "\n",
        "        y_hat_T = self.decoder(Y, X_encoded)\n",
        "        # -> (batch_size, y_dim)\n",
        "\n",
        "        return y_hat_T\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'T': self.T,\n",
        "            'm': self.m,\n",
        "            'p': self.p,\n",
        "            'd': self.d,\n",
        "            'y_dim': self.y_dim\n",
        "        }"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmB4dzMOJSrW",
        "outputId": "ca204000-5e0f-440f-a6f3-e31c479f62ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UzkBzVWJ8Dn"
      },
      "source": [
        "dataroot = '/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv'"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C3haGE5KB4j",
        "outputId": "a6badf56-69fb-44f1-a87c-4529e86549ab"
      },
      "source": [
        "!ls '/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv'"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/aml_project/data/nasdaq100_padding.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZn_ZT1qKQi1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_data(input_path, debug=True): \n",
        "#   Each feature item of the dataset should be of shape (batch_size, T, length_of_driving_series + y_dim)\n",
        "\n",
        "# And each label item of the dataset should be of shape (batch_size, y_dim)\n",
        "\n",
        "# Development\n",
        "    \"\"\"Read nasdaq stocks data.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): directory to nasdaq dataset.\n",
        "\n",
        "    Returns:\n",
        "        X (np.ndarray): features.\n",
        "        y (np.ndarray): ground truth.\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path, nrows=32*10 if debug else None)\n",
        "    # X = df.iloc[:, 0:-1].values\n",
        "    X = df.loc[:, [x for x in df.columns.tolist()]].to_numpy() #values() #as_matrix() #nxT\n",
        "    # y = df.iloc[:, -1].values\n",
        "    # y = np.array(df.NDX) #n-1 values, nth value btani hai\n",
        "\n",
        "    return X"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcWL2v1PMKzf"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "features = read_data(dataroot, debug=False)\n",
        "scale = StandardScaler().fit(features)\n",
        "features = scale.transform(features)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H01TQtQW8R5_",
        "outputId": "2440c6bf-63a3-40ee-950a-dc88b223a2c9"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40560, 82)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rMtELNCSssC",
        "outputId": "507391ae-915a-4f54-9e17-0fd161dcc76e"
      },
      "source": [
        "features"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.82166581, -3.42991957, -1.60918711, ..., -1.86674079,\n",
              "        -2.14183171, -2.35353513],\n",
              "       [-0.83220311, -3.40824969, -1.60918711, ..., -1.81032478,\n",
              "        -2.06400103, -2.35353513],\n",
              "       [-0.83792335, -3.3938031 , -1.66989855, ..., -1.70183245,\n",
              "        -2.05801406, -2.34133626],\n",
              "       ...,\n",
              "       [ 1.87717227,  1.16289176,  0.06697655, ...,  3.04774477,\n",
              "        -1.84344086,  1.7048016 ],\n",
              "       [ 1.88362367,  1.1737267 ,  0.07753506, ...,  3.0501316 ,\n",
              "        -1.84547643,  1.72163035],\n",
              "       [ 1.88362367,  1.17131893,  0.0722558 , ...,  3.05447129,\n",
              "        -1.84248294,  1.72151974]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADDhTHffNNmD"
      },
      "source": [
        "# !pip install get-rolling-window\n",
        "BATCH_SIZE = 256\n",
        "WINDOW_SIZE = 10\n",
        "ENCODER_HIDDEN_STATES = 128\n",
        "DECODER_HIDDEN_STATES = 128\n",
        "\n",
        "Y_DIM = 1\n",
        "\n",
        "DATA = 'nasdaq100_padding.csv'\n",
        "\n",
        "VALIDATION_RATIO = 0.2\n",
        "\n",
        "EPOCHS = 20"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD3Sy1GoMoao",
        "outputId": "0d6006bc-674e-4852-c090-b80e70883b38"
      },
      "source": [
        "def get_labels_from_features(features):\n",
        "    return features[WINDOW_SIZE - 1:, -Y_DIM:][:, None, :]\n",
        "\n",
        "\n",
        "def split_by_ratio(features):\n",
        "    length = len(features)\n",
        "    validation_length = int(VALIDATION_RATIO * length)\n",
        "    \n",
        "    return features[:-validation_length], features[-validation_length:]\n",
        "\n",
        "\n",
        "training_features, validation_features = split_by_ratio(features)\n",
        "\n",
        "print('training length', len(training_features))\n",
        "print('validation length', len(validation_features))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training length 32448\n",
            "validation length 8112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q71TAsnZM2oY",
        "outputId": "721b4e2f-bdf5-4fa4-89d3-d5d4fed66a67"
      },
      "source": [
        "import tensorflow as tf\n",
        "from get_rolling_window import rolling_window\n",
        "\n",
        "train_f, train_l = rolling_window(training_features, WINDOW_SIZE, 1), get_labels_from_features(training_features)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_f, train_l)).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print(train_f.shape, train_l.shape)\n",
        "\n",
        "val_f, val_l = rolling_window(validation_features, WINDOW_SIZE, 1), get_labels_from_features(validation_features)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_f, val_l)).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "train_ds"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32439, 10, 82) (32439, 1, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 10, 82), (256, 1, 1)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyy-5S-2NlqL"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "model = DARNN(\n",
        "    T = WINDOW_SIZE,\n",
        "    m = ENCODER_HIDDEN_STATES,\n",
        "    d = ENCODER_HIDDEN_STATES,\n",
        "    p = DECODER_HIDDEN_STATES,\n",
        "    y_dim = Y_DIM,\n",
        "    lmu = False\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mape']\n",
        ")"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I0iDqj5NmuB",
        "outputId": "d5139b39-ea74-486c-dee0-76389be6d06d"
      },
      "source": [
        "feature_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "print('feature, label shape', feature_batch.shape, label_batch.shape)\n",
        "\n",
        "print('prediction shape', model(feature_batch).shape)\n",
        "\n",
        "model(feature_batch[:1])\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature, label shape (256, 10, 82) (256, 1, 1)\n",
            "prediction shape (256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01145553]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zox6waqqUhoS"
      },
      "source": [
        "# model = DARNN(T=int(10), m=int(128), p=128, lmu=False)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlDGB2IWNqlz",
        "outputId": "67e02b0c-e3f4-43ef-95e9-629c2985c18f"
      },
      "source": [
        "save_to = './checkpoint.hdf5'\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[\n",
        "        # Save checkpoints on best validation loss\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            save_to,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Stop early if the model overfits\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    ],\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 29s 71ms/step - loss: 0.7241 - mae: 0.6136 - mape: 253.8419 - val_loss: 0.0320 - val_mae: 0.1482 - val_mape: 22.4998\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03200, saving model to ./checkpoint.hdf5\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0528 - mae: 0.1610 - mape: 82.0470 - val_loss: 0.0125 - val_mae: 0.0880 - val_mape: 14.5107\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.03200 to 0.01252, saving model to ./checkpoint.hdf5\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0054 - mae: 0.0549 - mape: 31.7279 - val_loss: 0.0078 - val_mae: 0.0733 - val_mape: 9.4257\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01252 to 0.00783, saving model to ./checkpoint.hdf5\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0026 - mae: 0.0360 - mape: 29.4314 - val_loss: 0.0070 - val_mae: 0.0659 - val_mape: 7.5026\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00783 to 0.00699, saving model to ./checkpoint.hdf5\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0021 - mae: 0.0302 - mape: 25.4273 - val_loss: 0.0070 - val_mae: 0.0663 - val_mape: 7.1345\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00699 to 0.00696, saving model to ./checkpoint.hdf5\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0035 - mae: 0.0433 - mape: 34.3474 - val_loss: 0.0058 - val_mae: 0.0607 - val_mape: 6.7610\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00696 to 0.00583, saving model to ./checkpoint.hdf5\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0076 - mae: 0.0686 - mape: 47.3006 - val_loss: 0.0071 - val_mae: 0.0663 - val_mape: 6.9227\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00583\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0122 - mae: 0.0869 - mape: 51.8074 - val_loss: 0.0079 - val_mae: 0.0750 - val_mape: 9.0657\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00583\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0187 - mae: 0.1061 - mape: 55.7665 - val_loss: 0.0095 - val_mae: 0.0830 - val_mape: 11.4676\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00583\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0176 - mae: 0.1012 - mape: 51.5428 - val_loss: 0.0053 - val_mae: 0.0541 - val_mape: 8.6539\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00583 to 0.00529, saving model to ./checkpoint.hdf5\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0116 - mae: 0.0822 - mape: 44.8960 - val_loss: 0.0049 - val_mae: 0.0531 - val_mape: 8.0256\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00529 to 0.00492, saving model to ./checkpoint.hdf5\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0061 - mae: 0.0595 - mape: 35.2855 - val_loss: 0.0064 - val_mae: 0.0650 - val_mape: 8.5894\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00492\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0028 - mae: 0.0397 - mape: 26.8460 - val_loss: 0.0063 - val_mae: 0.0641 - val_mape: 8.5044\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00492\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0025 - mae: 0.0376 - mape: 26.3552 - val_loss: 0.0031 - val_mae: 0.0427 - val_mape: 6.4754\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00492 to 0.00312, saving model to ./checkpoint.hdf5\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0042 - mae: 0.0502 - mape: 28.7072 - val_loss: 0.0038 - val_mae: 0.0471 - val_mape: 5.5880\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00312\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0055 - mae: 0.0560 - mape: 29.6065 - val_loss: 0.0045 - val_mae: 0.0524 - val_mape: 5.7071\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00312\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0050 - mae: 0.0525 - mape: 28.8535 - val_loss: 0.0031 - val_mae: 0.0429 - val_mape: 5.3584\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00312\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.0039 - mae: 0.0463 - mape: 27.9464 - val_loss: 0.0026 - val_mae: 0.0384 - val_mape: 5.6132\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00312 to 0.00258, saving model to ./checkpoint.hdf5\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0034 - mae: 0.0424 - mape: 27.6850 - val_loss: 0.0028 - val_mae: 0.0409 - val_mape: 6.5230\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00258\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.0031 - mae: 0.0405 - mape: 27.9830 - val_loss: 0.0034 - val_mae: 0.0457 - val_mape: 7.4476\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFolXFrON218",
        "outputId": "667661cc-4934-4b2a-c9c1-50d7ece55fca"
      },
      "source": [
        "model.count_params()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259601"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJLmHncST_cO",
        "outputId": "d548a9d2-2f2e-4ca7-fe3c-d15e4a67785c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"DARNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (Encoder)      multiple                  110221    \n",
            "_________________________________________________________________\n",
            "decoder (Decoder)            multiple                  149380    \n",
            "=================================================================\n",
            "Total params: 259,601\n",
            "Trainable params: 259,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrgs8HY1Ia6v",
        "outputId": "8969f712-10a8-4a9f-e011-a21fb0658205"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(keras_lmu)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras_lmu' from '/content/keras-lmu/keras_lmu/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p71pbnfgAdQQ"
      },
      "source": [
        "model_lmu = DARNN(\n",
        "    T = WINDOW_SIZE,\n",
        "    m = ENCODER_HIDDEN_STATES,\n",
        "    d = 4,\n",
        "    p = DECODER_HIDDEN_STATES,\n",
        "    y_dim = Y_DIM,\n",
        "    lmu = True\n",
        ")\n",
        "\n",
        "model_lmu.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mape']\n",
        ")"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tn7rvPqAnsT",
        "outputId": "ece3a662-efc4-4ad7-f89a-e03bb34ee446"
      },
      "source": [
        "feature_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "print('feature, label shape', feature_batch.shape, label_batch.shape)\n",
        "\n",
        "print('prediction shape', model_lmu(feature_batch).shape)\n",
        "\n",
        "model_lmu(feature_batch[:1])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature, label shape (256, 10, 82) (256, 1, 1)\n",
            "prediction shape (256, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.13783102]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFo1NMAiMnt2",
        "outputId": "108a8c0f-785c-40b3-d3f2-6ac3a37e4c4f"
      },
      "source": [
        "save_to = './checkpoint.hdf5'\n",
        "\n",
        "history = model_lmu.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[\n",
        "        # Save checkpoints on best validation loss\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            save_to,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        # Stop early if the model overfits\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    ],\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 10s 29ms/step - loss: 0.4528 - mae: 0.4643 - mape: 168.6424 - val_loss: 0.0575 - val_mae: 0.1945 - val_mape: 25.7359\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.05753, saving model to ./checkpoint.hdf5\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0373 - mae: 0.1393 - mape: 74.0155 - val_loss: 0.0159 - val_mae: 0.1018 - val_mape: 12.3046\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.05753 to 0.01593, saving model to ./checkpoint.hdf5\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0309 - mae: 0.1350 - mape: 60.4076 - val_loss: 0.0137 - val_mae: 0.0870 - val_mape: 13.8654\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01593 to 0.01369, saving model to ./checkpoint.hdf5\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0412 - mae: 0.1348 - mape: 49.9264 - val_loss: 0.1819 - val_mae: 0.3584 - val_mape: 31.2688\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01369\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0996 - mae: 0.1924 - mape: 61.3524 - val_loss: 0.3119 - val_mae: 0.4787 - val_mape: 42.7740\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01369\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0370 - mae: 0.1287 - mape: 45.4671 - val_loss: 0.0306 - val_mae: 0.1366 - val_mape: 11.7949\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01369\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0137 - mae: 0.0921 - mape: 44.8239 - val_loss: 0.0195 - val_mae: 0.1134 - val_mape: 11.6032\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01369\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0081 - mae: 0.0686 - mape: 38.8865 - val_loss: 0.0054 - val_mae: 0.0543 - val_mape: 8.1787\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01369 to 0.00537, saving model to ./checkpoint.hdf5\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0095 - mae: 0.0752 - mape: 48.4795 - val_loss: 0.0053 - val_mae: 0.0574 - val_mape: 8.2627\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00537 to 0.00531, saving model to ./checkpoint.hdf5\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0026 - mae: 0.0394 - mape: 26.8157 - val_loss: 0.0038 - val_mae: 0.0485 - val_mape: 6.3484\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00531 to 0.00380, saving model to ./checkpoint.hdf5\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0016 - mae: 0.0283 - mape: 26.9402 - val_loss: 0.0107 - val_mae: 0.0802 - val_mape: 7.4908\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00380\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0030 - mae: 0.0418 - mape: 26.6765 - val_loss: 0.0041 - val_mae: 0.0507 - val_mape: 6.9479\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00380\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0128 - mae: 0.0886 - mape: 48.1009 - val_loss: 0.0076 - val_mae: 0.0744 - val_mape: 9.2362\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00380\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0020 - mae: 0.0332 - mape: 23.8588 - val_loss: 0.0035 - val_mae: 0.0458 - val_mape: 6.9691\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00380 to 0.00355, saving model to ./checkpoint.hdf5\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0021 - mae: 0.0357 - mape: 23.6337 - val_loss: 0.0122 - val_mae: 0.0924 - val_mape: 9.9230\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00355\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0036 - mae: 0.0461 - mape: 33.2384 - val_loss: 0.0146 - val_mae: 0.1005 - val_mape: 10.4491\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00355\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0018 - mae: 0.0315 - mape: 20.1124 - val_loss: 0.0062 - val_mae: 0.0681 - val_mape: 8.5233\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00355\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0037 - mae: 0.0472 - mape: 32.1416 - val_loss: 0.0142 - val_mae: 0.1012 - val_mape: 12.0997\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00355\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0048 - mae: 0.0538 - mape: 35.4259 - val_loss: 0.0184 - val_mae: 0.1194 - val_mape: 13.4541\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00355\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.0023 - mae: 0.0371 - mape: 21.7680 - val_loss: 0.0023 - val_mae: 0.0388 - val_mape: 6.2045\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00355 to 0.00229, saving model to ./checkpoint.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSLzbdqxEyBi",
        "outputId": "0cb6326d-f876-4d37-fd61-d04e54e573d1"
      },
      "source": [
        "model_lmu.count_params()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCWZ7svwE1Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b471df0e-7344-4a8f-bc22-d6ed8744e294"
      },
      "source": [
        "model_lmu.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"DARNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (Encoder)      multiple                  30853     \n",
            "_________________________________________________________________\n",
            "decoder (Decoder)            multiple                  87196     \n",
            "=================================================================\n",
            "Total params: 118,049\n",
            "Trainable params: 118,009\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO_ynP2HKs8X"
      },
      "source": [
        "# import numpy as np \n",
        "# import pandas as pd \n",
        "# # Read dataset\n",
        "# print(\"==> Load dataset ...\")\n",
        "# X, y = read_data(dataroot, debug=False)\n",
        "\n",
        "# # Initialize model\n",
        "# print(\"==> Initialize DA-RNN model ...\")\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredError, metrics=[\"accuracy\"]) \n",
        "# #[12:37 AM] Mohammad Ali Rehan\n",
        "\n",
        "# model.fit(\n",
        "#     (X, y),\n",
        "#     validation_data=None,\n",
        "#     epochs=100,\n",
        "#     verbose=1\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryMiuw-HK8pC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}